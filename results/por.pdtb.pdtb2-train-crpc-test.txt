nohup: ignoring input and appending output to 'nohup.out'
/home/VD/peterb/python/lib/python3.10/site-packages/torch_geometric/typing.py:47: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: /lib/x86_64-linux-gnu/libm.so.6: version `GLIBC_2.29' not found (required by /local/home/VD/peterb/python/lib/python3.10/site-packages/libpyg.so)
  warnings.warn(f"An issue occurred while importing 'pyg-lib'. "
/home/VD/peterb/python/lib/python3.10/site-packages/torch_geometric/typing.py:101: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /lib/x86_64-linux-gnu/libm.so.6: version `GLIBC_2.29' not found (required by /local/home/VD/peterb/python/lib/python3.10/site-packages/libpyg.so)
  warnings.warn(f"An issue occurred while importing 'torch-sparse'. "
{'cuda': 0, 'seed': 0, 'data_file': 'data/pdtb_pt_train_crpc_test/data/', 'log_file': 'data/pdtb_pt_train_crpc_test/log/', 'save_file': 'data/pdtb_pt_train_crpc_test/saved_dict/', 'model_name_or_path': 'xlm-roberta-base', 'freeze_bert': False, 'temperature': 0.1, 'num_co_attention_layer': 2, 'num_gcn_layer': 2, 'gcn_dropout': 0.1, 'label_embedding_size': 100, 'lambda_global': 0.1, 'lambda_local': 1.0, 'pad_size': 100, 'batch_size': 32, 'epoch': 30, 'lr': 1e-05, 'warmup_ratio': 0.05, 'evaluate_steps': 100, 'require_improvement': 10000, 'i2top': '', 'top2i': '', 'n_top': 4, 'i2sec': '', 'sec2i': '', 'n_sec': 11, 'i2conn': '', 'conn2i': '', 'n_conn': 102, 'label_num': 117, 'tokenizer': '', 'config': '', 't': 'March07-19:18:02', 'log': 'data/pdtb_pt_train_crpc_test/log/March07-19:18:02.log', 'device': device(type='cuda', index=0)}
Loading data...
0it [00:00, ?it/s]113it [00:00, 1128.19it/s]304it [00:00, 1584.69it/s]493it [00:00, 1722.73it/s]696it [00:00, 1843.57it/s]902it [00:00, 1918.80it/s]1094it [00:00, 1916.75it/s]1298it [00:00, 1953.75it/s]1494it [00:00, 1954.63it/s]1690it [00:00, 1886.59it/s]1880it [00:01, 1879.98it/s]2075it [00:01, 1900.27it/s]2266it [00:01, 1888.57it/s]2456it [00:01, 1839.12it/s]2649it [00:01, 1864.56it/s]2836it [00:01, 1839.75it/s]3022it [00:01, 1843.83it/s]3207it [00:01, 1844.56it/s]3401it [00:01, 1871.74it/s]3589it [00:01, 1840.85it/s]3779it [00:02, 1857.32it/s]3965it [00:02, 1837.86it/s]4149it [00:02, 1838.01it/s]4333it [00:02, 1789.39it/s]4521it [00:02, 1814.17it/s]4703it [00:02, 1814.30it/s]4885it [00:02, 1747.71it/s]5071it [00:02, 1758.78it/s]5248it [00:03, 1194.83it/s]5397it [00:03, 1258.43it/s]5598it [00:03, 1436.80it/s]5786it [00:03, 1548.34it/s]5988it [00:03, 1672.05it/s]6175it [00:03, 1725.27it/s]6366it [00:03, 1776.07it/s]6551it [00:03, 1769.15it/s]6737it [00:03, 1794.39it/s]6920it [00:03, 1802.55it/s]7104it [00:04, 1811.50it/s]7294it [00:04, 1836.72it/s]7479it [00:04, 1800.28it/s]7662it [00:04, 1806.84it/s]7857it [00:04, 1845.29it/s]8043it [00:04, 1809.83it/s]8230it [00:04, 1826.39it/s]8414it [00:04, 1786.96it/s]8597it [00:04, 1798.37it/s]8793it [00:04, 1845.79it/s]8978it [00:05, 1824.98it/s]9171it [00:05, 1853.98it/s]9357it [00:05, 1831.51it/s]9541it [00:05, 1813.98it/s]9724it [00:05, 1817.39it/s]9906it [00:05, 1810.60it/s]10088it [00:05, 1791.83it/s]10268it [00:05, 1771.34it/s]10467it [00:05, 1832.43it/s]10651it [00:05, 1832.63it/s]10835it [00:06, 1833.06it/s]11026it [00:06, 1854.65it/s]11212it [00:06, 1824.93it/s]11408it [00:06, 1863.49it/s]11597it [00:06, 1869.51it/s]11786it [00:06, 1874.04it/s]11974it [00:06, 1870.57it/s]12162it [00:06, 1764.49it/s]12343it [00:06, 1777.17it/s]12522it [00:07, 1771.86it/s]12547it [00:07, 1783.22it/s]
0it [00:00, ?it/s]181it [00:00, 1805.22it/s]362it [00:00, 1807.63it/s]549it [00:00, 1833.92it/s]733it [00:00, 1790.77it/s]913it [00:00, 1776.38it/s]1091it [00:00, 1768.17it/s]1165it [00:00, 1786.78it/s]
0it [00:00, ?it/s]154it [00:00, 1526.84it/s]307it [00:00, 1473.48it/s]455it [00:00, 1398.71it/s]596it [00:00, 1401.23it/s]636it [00:00, 1423.06it/s]
Time usage: 17.59763240814209
https://huggingface.co:443 "HEAD /xlm-roberta-base/resolve/main/config.json HTTP/1.1" 200 0
Epoch [1/30]
top-down:TOP: Iter:    100,  Train Loss: 3.1e+01,  Train Acc: 56.25%,Val Loss:   7.5,  Val Acc: 55.88%, Val F1: 17.92% Time: 87.09920406341553 *
top-down:SEC: Iter:    100,  Train Loss: 3.1e+01,  Train Acc: 21.88%,Val Loss:   7.5,  Val Acc: 24.21%, Val F1:  3.54% Time: 87.09920406341553 *
top-down:CONN: Iter:    100,  Train Loss: 3.1e+01,  Train Acc:  0.00%,Val Loss:   7.5,  Val Acc: 12.79%, Val F1:  0.34% Time: 87.09920406341553 *
 
 
top-down:TOP: Iter:    200,  Train Loss: 3.1e+01,  Train Acc: 56.25%,Val Loss:   6.6,  Val Acc: 55.62%, Val F1: 18.04% Time: 167.30786728858948 *
top-down:SEC: Iter:    200,  Train Loss: 3.1e+01,  Train Acc: 31.25%,Val Loss:   6.6,  Val Acc: 28.67%, Val F1:  6.66% Time: 167.30786728858948 *
top-down:CONN: Iter:    200,  Train Loss: 3.1e+01,  Train Acc: 12.50%,Val Loss:   6.6,  Val Acc: 12.88%, Val F1:  0.34% Time: 167.30786728858948 *
 
 
top-down:TOP: Iter:    300,  Train Loss: 4e+01,  Train Acc: 68.75%,Val Loss:   6.4,  Val Acc: 55.71%, Val F1: 26.36% Time: 247.70088648796082 *
top-down:SEC: Iter:    300,  Train Loss: 4e+01,  Train Acc: 25.00%,Val Loss:   6.4,  Val Acc: 31.59%, Val F1: 10.05% Time: 247.70088648796082 *
top-down:CONN: Iter:    300,  Train Loss: 4e+01,  Train Acc: 15.62%,Val Loss:   6.4,  Val Acc: 16.31%, Val F1:  1.06% Time: 247.70088648796082 *
 
 
Train time usage: 320.251473903656
Test time usage: 1.0938482284545898
TOP: Test Loss:   6.1,  Test Acc: 56.92%, Test F1: 21.55%
SEC: Test Loss:   6.1,  Test Acc: 10.22%, Test F1:  6.29%
CONN: Test Loss:   6.1,  Test Acc: 10.22%, Test F1:  6.18%
consistency_top_sec:  3.37%,  consistency_sec_conn:  1.83%, consistency_top_sec_conn:  1.83%
              precision    recall  f1-score   support

    Temporal     0.0000    0.0000    0.0000        70
 Contingency     0.4000    0.0825    0.1368        97
  Comparison     0.0000    0.0000    0.0000       109
   Expansion     0.5747    0.9833    0.7254       360

    accuracy                         0.5692       636
   macro avg     0.2437    0.2665    0.2155       636
weighted avg     0.3863    0.5692    0.4315       636

                             precision    recall  f1-score   support

      Temporal.Asynchronous     0.0000    0.0000    0.0000        70
         Temporal.Synchrony     0.2468    0.3918    0.3028        97
          Contingency.Cause     0.0000    0.0000    0.0000         5
Contingency.Pragmatic cause     0.0000    0.0000    0.0000       104
        Comparison.Contrast     0.5625    0.0783    0.1374       345
      Comparison.Concession     0.0000    0.0000    0.0000        15

                  micro avg     0.3218    0.1022    0.1551       636
                  macro avg     0.1349    0.0783    0.0734       636
               weighted avg     0.3428    0.1022    0.1207       636

Epoch [2/30]
top-down:TOP: Iter:    400,  Train Loss: 3e+01,  Train Acc: 46.88%,Val Loss:   6.2,  Val Acc: 55.11%, Val F1: 27.53% Time: 8.854686975479126 *
top-down:SEC: Iter:    400,  Train Loss: 3e+01,  Train Acc: 31.25%,Val Loss:   6.2,  Val Acc: 34.25%, Val F1: 10.84% Time: 8.854686975479126 *
top-down:CONN: Iter:    400,  Train Loss: 3e+01,  Train Acc:  9.38%,Val Loss:   6.2,  Val Acc: 17.17%, Val F1:  1.14% Time: 8.854686975479126 *
 
 
top-down:TOP: Iter:    500,  Train Loss: 3.2e+01,  Train Acc: 50.00%,Val Loss:   6.2,  Val Acc: 49.79%, Val F1: 27.37% Time: 88.92395806312561 *
top-down:SEC: Iter:    500,  Train Loss: 3.2e+01,  Train Acc: 34.38%,Val Loss:   6.2,  Val Acc: 35.54%, Val F1: 13.48% Time: 88.92395806312561 *
top-down:CONN: Iter:    500,  Train Loss: 3.2e+01,  Train Acc: 18.75%,Val Loss:   6.2,  Val Acc: 19.57%, Val F1:  1.85% Time: 88.92395806312561 *
 
 
top-down:TOP: Iter:    600,  Train Loss: 3.2e+01,  Train Acc: 46.88%,Val Loss:   6.0,  Val Acc: 53.91%, Val F1: 29.44% Time: 169.0651717185974 *
top-down:SEC: Iter:    600,  Train Loss: 3.2e+01,  Train Acc: 53.12%,Val Loss:   6.0,  Val Acc: 38.11%, Val F1: 16.06% Time: 169.0651717185974 *
top-down:CONN: Iter:    600,  Train Loss: 3.2e+01,  Train Acc: 25.00%,Val Loss:   6.0,  Val Acc: 20.09%, Val F1:  2.08% Time: 169.0651717185974 *
 
 
top-down:TOP: Iter:    700,  Train Loss: 3e+01,  Train Acc: 43.75%,Val Loss:   5.8,  Val Acc: 54.42%, Val F1: 37.43% Time: 249.17535638809204 *
top-down:SEC: Iter:    700,  Train Loss: 3e+01,  Train Acc: 31.25%,Val Loss:   5.8,  Val Acc: 40.00%, Val F1: 16.65% Time: 249.17535638809204 *
top-down:CONN: Iter:    700,  Train Loss: 3e+01,  Train Acc: 28.12%,Val Loss:   5.8,  Val Acc: 21.80%, Val F1:  2.51% Time: 249.17535638809204 *
 
 
Train time usage: 316.22470355033875
Test time usage: 1.1082861423492432
TOP: Test Loss:   5.4,  Test Acc: 55.50%, Test F1: 34.97%
SEC: Test Loss:   5.4,  Test Acc: 38.21%, Test F1: 28.05%
CONN: Test Loss:   5.4,  Test Acc: 31.13%, Test F1:  4.32%
consistency_top_sec: 20.02%,  consistency_sec_conn: 12.32%, consistency_top_sec_conn: 12.22%
              precision    recall  f1-score   support

    Temporal     0.4348    0.2857    0.3448        70
 Contingency     0.2444    0.2268    0.2353        97
  Comparison     0.7500    0.0550    0.1026       109
   Expansion     0.6199    0.8472    0.7160       360

    accuracy                         0.5550       636
   macro avg     0.5123    0.3537    0.3497       636
weighted avg     0.5646    0.5550    0.4967       636

                             precision    recall  f1-score   support

      Temporal.Asynchronous     0.3478    0.3429    0.3453        70
         Temporal.Synchrony     0.2477    0.5464    0.3408        97
          Contingency.Cause     0.1538    0.4000    0.2222         5
Contingency.Pragmatic cause     0.0000    0.0000    0.0000       104
        Comparison.Contrast     0.6542    0.4551    0.5368       345
      Comparison.Concession     0.5833    0.4667    0.5185        15

                  micro avg     0.4434    0.3821    0.4105       636
                  macro avg     0.3311    0.3685    0.3273       636
               weighted avg     0.4459    0.3821    0.3951       636

Epoch [3/30]
top-down:TOP: Iter:    800,  Train Loss: 2.8e+01,  Train Acc: 50.00%,Val Loss:   5.7,  Val Acc: 54.42%, Val F1: 46.37% Time: 14.235144853591919 *
top-down:SEC: Iter:    800,  Train Loss: 2.8e+01,  Train Acc: 31.25%,Val Loss:   5.7,  Val Acc: 43.18%, Val F1: 22.23% Time: 14.235144853591919 *
top-down:CONN: Iter:    800,  Train Loss: 2.8e+01,  Train Acc: 21.88%,Val Loss:   5.7,  Val Acc: 22.15%, Val F1:  3.75% Time: 14.235144853591919 *
 
 
top-down:TOP: Iter:    900,  Train Loss: 2.9e+01,  Train Acc: 71.88%,Val Loss:   5.6,  Val Acc: 59.40%, Val F1: 45.74% Time: 94.63299107551575 *
top-down:SEC: Iter:    900,  Train Loss: 2.9e+01,  Train Acc: 53.12%,Val Loss:   5.6,  Val Acc: 44.46%, Val F1: 24.36% Time: 94.63299107551575 *
top-down:CONN: Iter:    900,  Train Loss: 2.9e+01,  Train Acc:  9.38%,Val Loss:   5.6,  Val Acc: 23.52%, Val F1:  3.69% Time: 94.63299107551575 *
 
 
top-down:TOP: Iter:   1000,  Train Loss: 3e+01,  Train Acc: 75.00%,Val Loss:   5.5,  Val Acc: 60.94%, Val F1: 44.90% Time: 174.9081437587738 *
top-down:SEC: Iter:   1000,  Train Loss: 3e+01,  Train Acc: 56.25%,Val Loss:   5.5,  Val Acc: 46.27%, Val F1: 23.49% Time: 174.9081437587738 *
top-down:CONN: Iter:   1000,  Train Loss: 3e+01,  Train Acc: 34.38%,Val Loss:   5.5,  Val Acc: 24.72%, Val F1:  4.22% Time: 174.9081437587738 *
 
 
top-down:TOP: Iter:   1100,  Train Loss: 3.1e+01,  Train Acc: 62.50%,Val Loss:   5.5,  Val Acc: 61.37%, Val F1: 48.68% Time: 254.94023156166077 *
top-down:SEC: Iter:   1100,  Train Loss: 3.1e+01,  Train Acc: 53.12%,Val Loss:   5.5,  Val Acc: 46.52%, Val F1: 23.78% Time: 254.94023156166077 *
top-down:CONN: Iter:   1100,  Train Loss: 3.1e+01,  Train Acc: 43.75%,Val Loss:   5.5,  Val Acc: 24.72%, Val F1:  4.30% Time: 254.94023156166077 *
 
 
Train time usage: 316.627729177475
Test time usage: 1.115807056427002
TOP: Test Loss:   5.3,  Test Acc: 59.28%, Test F1: 45.22%
SEC: Test Loss:   5.3,  Test Acc: 46.23%, Test F1: 27.69%
CONN: Test Loss:   5.3,  Test Acc: 31.45%, Test F1:  3.99%
consistency_top_sec: 25.89%,  consistency_sec_conn: 15.01%, consistency_top_sec_conn: 14.92%
              precision    recall  f1-score   support

    Temporal     0.4510    0.3286    0.3802        70
 Contingency     0.4430    0.3608    0.3977        97
  Comparison     0.4630    0.2294    0.3067       109
   Expansion     0.6504    0.8167    0.7241       360

    accuracy                         0.5928       636
   macro avg     0.5019    0.4339    0.4522       636
weighted avg     0.5647    0.5928    0.5650       636

                             precision    recall  f1-score   support

      Temporal.Asynchronous     0.4464    0.3571    0.3968        70
         Temporal.Synchrony     0.3448    0.5155    0.4132        97
          Contingency.Cause     0.0455    0.6000    0.0845         5
Contingency.Pragmatic cause     0.0000    0.0000    0.0000       104
        Comparison.Contrast     0.6752    0.6145    0.6434       345
      Comparison.Concession     0.8000    0.2667    0.4000        15

                  micro avg     0.5017    0.4623    0.4812       636
                  macro avg     0.3853    0.3923    0.3230       636
               weighted avg     0.4872    0.4623    0.4658       636

Epoch [4/30]
top-down:TOP: Iter:   1200,  Train Loss: 3.3e+01,  Train Acc: 78.12%,Val Loss:   5.4,  Val Acc: 61.63%, Val F1: 49.92% Time: 19.6866717338562 *
top-down:SEC: Iter:   1200,  Train Loss: 3.3e+01,  Train Acc: 68.75%,Val Loss:   5.4,  Val Acc: 48.33%, Val F1: 25.12% Time: 19.6866717338562 *
top-down:CONN: Iter:   1200,  Train Loss: 3.3e+01,  Train Acc: 37.50%,Val Loss:   5.4,  Val Acc: 26.95%, Val F1:  5.19% Time: 19.6866717338562 *
 
 
top-down:TOP: Iter:   1300,  Train Loss: 3.5e+01,  Train Acc: 71.88%,Val Loss:   5.4,  Val Acc: 62.66%, Val F1: 48.65% Time: 99.98666310310364 *
top-down:SEC: Iter:   1300,  Train Loss: 3.5e+01,  Train Acc: 56.25%,Val Loss:   5.4,  Val Acc: 48.50%, Val F1: 27.94% Time: 99.98666310310364 *
top-down:CONN: Iter:   1300,  Train Loss: 3.5e+01,  Train Acc: 43.75%,Val Loss:   5.4,  Val Acc: 26.18%, Val F1:  4.97% Time: 99.98666310310364 *
 
 
top-down:TOP: Iter:   1400,  Train Loss: 2.7e+01,  Train Acc: 71.88%,Val Loss:   5.5,  Val Acc: 61.03%, Val F1: 52.41% Time: 180.2814440727234 *
top-down:SEC: Iter:   1400,  Train Loss: 2.7e+01,  Train Acc: 62.50%,Val Loss:   5.5,  Val Acc: 46.78%, Val F1: 29.72% Time: 180.2814440727234 *
top-down:CONN: Iter:   1400,  Train Loss: 2.7e+01,  Train Acc: 46.88%,Val Loss:   5.5,  Val Acc: 26.52%, Val F1:  4.97% Time: 180.2814440727234 *
 
 
top-down:TOP: Iter:   1500,  Train Loss: 3.4e+01,  Train Acc: 59.38%,Val Loss:   5.5,  Val Acc: 60.60%, Val F1: 49.41% Time: 258.8299448490143 
top-down:SEC: Iter:   1500,  Train Loss: 3.4e+01,  Train Acc: 40.62%,Val Loss:   5.5,  Val Acc: 46.70%, Val F1: 27.12% Time: 258.8299448490143 
top-down:CONN: Iter:   1500,  Train Loss: 3.4e+01,  Train Acc: 25.00%,Val Loss:   5.5,  Val Acc: 26.70%, Val F1:  5.70% Time: 258.8299448490143 
 
 
Train time usage: 314.95507740974426
Test time usage: 1.0899298191070557
TOP: Test Loss:   5.7,  Test Acc: 58.96%, Test F1: 42.92%
SEC: Test Loss:   5.7,  Test Acc: 35.53%, Test F1: 22.36%
CONN: Test Loss:   5.7,  Test Acc: 24.21%, Test F1:  2.44%
consistency_top_sec: 19.73%,  consistency_sec_conn:  8.57%, consistency_top_sec_conn:  8.57%
              precision    recall  f1-score   support

    Temporal     0.5556    0.2143    0.3093        70
 Contingency     0.4040    0.4124    0.4082        97
  Comparison     0.4884    0.1927    0.2763       109
   Expansion     0.6403    0.8306    0.7231       360

    accuracy                         0.5896       636
   macro avg     0.5221    0.4125    0.4292       636
weighted avg     0.5689    0.5896    0.5529       636

                             precision    recall  f1-score   support

      Temporal.Asynchronous     0.5152    0.2429    0.3301        70
         Temporal.Synchrony     0.3234    0.5567    0.4091        97
          Contingency.Cause     0.0577    0.6000    0.1053         5
Contingency.Pragmatic cause     0.0000    0.0000    0.0000       104
        Comparison.Contrast     0.6934    0.4261    0.5278       345
      Comparison.Concession     0.5556    0.3333    0.4167        15

                  micro avg     0.4778    0.3553    0.4076       636
                  macro avg     0.3575    0.3598    0.2982       636
               weighted avg     0.4957    0.3553    0.3957       636

Epoch [5/30]
top-down:TOP: Iter:   1600,  Train Loss: 3e+01,  Train Acc: 71.88%,Val Loss:   5.4,  Val Acc: 62.92%, Val F1: 51.67% Time: 24.939600944519043 *
top-down:SEC: Iter:   1600,  Train Loss: 3e+01,  Train Acc: 71.88%,Val Loss:   5.4,  Val Acc: 49.18%, Val F1: 30.39% Time: 24.939600944519043 *
top-down:CONN: Iter:   1600,  Train Loss: 3e+01,  Train Acc: 34.38%,Val Loss:   5.4,  Val Acc: 26.95%, Val F1:  5.49% Time: 24.939600944519043 *
 
 
top-down:TOP: Iter:   1700,  Train Loss: 3e+01,  Train Acc: 71.88%,Val Loss:   5.5,  Val Acc: 61.20%, Val F1: 50.83% Time: 103.3488221168518 
top-down:SEC: Iter:   1700,  Train Loss: 3e+01,  Train Acc: 53.12%,Val Loss:   5.5,  Val Acc: 48.07%, Val F1: 30.71% Time: 103.3488221168518 
top-down:CONN: Iter:   1700,  Train Loss: 3e+01,  Train Acc: 37.50%,Val Loss:   5.5,  Val Acc: 26.18%, Val F1:  5.48% Time: 103.3488221168518 
 
 
top-down:TOP: Iter:   1800,  Train Loss: 2.7e+01,  Train Acc: 78.12%,Val Loss:   5.5,  Val Acc: 60.43%, Val F1: 52.49% Time: 181.95700764656067 
top-down:SEC: Iter:   1800,  Train Loss: 2.7e+01,  Train Acc: 62.50%,Val Loss:   5.5,  Val Acc: 46.87%, Val F1: 29.30% Time: 181.95700764656067 
top-down:CONN: Iter:   1800,  Train Loss: 2.7e+01,  Train Acc: 43.75%,Val Loss:   5.5,  Val Acc: 26.61%, Val F1:  5.59% Time: 181.95700764656067 
 
 
top-down:TOP: Iter:   1900,  Train Loss: 2.7e+01,  Train Acc: 75.00%,Val Loss:   5.5,  Val Acc: 60.69%, Val F1: 50.61% Time: 260.86336970329285 
top-down:SEC: Iter:   1900,  Train Loss: 2.7e+01,  Train Acc: 46.88%,Val Loss:   5.5,  Val Acc: 46.27%, Val F1: 28.29% Time: 260.86336970329285 
top-down:CONN: Iter:   1900,  Train Loss: 2.7e+01,  Train Acc: 37.50%,Val Loss:   5.5,  Val Acc: 25.75%, Val F1:  5.50% Time: 260.86336970329285 
 
 
Train time usage: 311.6905052661896
Test time usage: 1.1233680248260498
TOP: Test Loss:   5.9,  Test Acc: 58.33%, Test F1: 46.03%
SEC: Test Loss:   5.9,  Test Acc: 39.15%, Test F1: 23.03%
CONN: Test Loss:   5.9,  Test Acc: 24.53%, Test F1:  2.19%
consistency_top_sec: 22.91%,  consistency_sec_conn: 10.39%, consistency_top_sec_conn: 10.39%
              precision    recall  f1-score   support

    Temporal     0.5161    0.2286    0.3168        70
 Contingency     0.3814    0.4639    0.4186        97
  Comparison     0.4744    0.3394    0.3957       109
   Expansion     0.6675    0.7583    0.7100       360

    accuracy                         0.5833       636
   macro avg     0.5098    0.4476    0.4603       636
weighted avg     0.5741    0.5833    0.5684       636

                             precision    recall  f1-score   support

      Temporal.Asynchronous     0.4865    0.2571    0.3364        70
         Temporal.Synchrony     0.3472    0.5155    0.4149        97
          Contingency.Cause     0.0482    0.8000    0.0909         5
Contingency.Pragmatic cause     0.0000    0.0000    0.0000       104
        Comparison.Contrast     0.7020    0.4986    0.5831       345
      Comparison.Concession     0.5556    0.3333    0.4167        15

                  micro avg     0.4807    0.3915    0.4315       636
                  macro avg     0.3566    0.4007    0.3070       636
               weighted avg     0.5008    0.3915    0.4271       636

Epoch [6/30]
top-down:TOP: Iter:   2000,  Train Loss: 2.8e+01,  Train Acc: 81.25%,Val Loss:   5.5,  Val Acc: 62.75%, Val F1: 51.74% Time: 28.6669020652771 
top-down:SEC: Iter:   2000,  Train Loss: 2.8e+01,  Train Acc: 71.88%,Val Loss:   5.5,  Val Acc: 48.50%, Val F1: 28.85% Time: 28.6669020652771 
top-down:CONN: Iter:   2000,  Train Loss: 2.8e+01,  Train Acc: 50.00%,Val Loss:   5.5,  Val Acc: 28.15%, Val F1:  6.54% Time: 28.6669020652771 
 
 
top-down:TOP: Iter:   2100,  Train Loss: 2.9e+01,  Train Acc: 81.25%,Val Loss:   5.6,  Val Acc: 62.23%, Val F1: 51.32% Time: 107.34910726547241 
top-down:SEC: Iter:   2100,  Train Loss: 2.9e+01,  Train Acc: 59.38%,Val Loss:   5.6,  Val Acc: 48.93%, Val F1: 29.71% Time: 107.34910726547241 
top-down:CONN: Iter:   2100,  Train Loss: 2.9e+01,  Train Acc: 40.62%,Val Loss:   5.6,  Val Acc: 26.70%, Val F1:  6.40% Time: 107.34910726547241 
 
 
top-down:TOP: Iter:   2200,  Train Loss: 2.7e+01,  Train Acc: 75.00%,Val Loss:   5.6,  Val Acc: 61.20%, Val F1: 49.77% Time: 186.2673408985138 
top-down:SEC: Iter:   2200,  Train Loss: 2.7e+01,  Train Acc: 62.50%,Val Loss:   5.6,  Val Acc: 48.33%, Val F1: 27.79% Time: 186.2673408985138 
top-down:CONN: Iter:   2200,  Train Loss: 2.7e+01,  Train Acc: 40.62%,Val Loss:   5.6,  Val Acc: 27.73%, Val F1:  6.39% Time: 186.2673408985138 
 
 
top-down:TOP: Iter:   2300,  Train Loss: 3.6e+01,  Train Acc: 81.25%,Val Loss:   5.7,  Val Acc: 60.43%, Val F1: 51.13% Time: 264.9714181423187 
top-down:SEC: Iter:   2300,  Train Loss: 3.6e+01,  Train Acc: 71.88%,Val Loss:   5.7,  Val Acc: 47.47%, Val F1: 29.47% Time: 264.9714181423187 
top-down:CONN: Iter:   2300,  Train Loss: 3.6e+01,  Train Acc: 34.38%,Val Loss:   5.7,  Val Acc: 26.95%, Val F1:  5.99% Time: 264.9714181423187 
 
 
Train time usage: 310.61543130874634
Test time usage: 1.100168228149414
TOP: Test Loss:   6.2,  Test Acc: 59.43%, Test F1: 45.99%
SEC: Test Loss:   6.2,  Test Acc: 38.52%, Test F1: 24.51%
CONN: Test Loss:   6.2,  Test Acc: 20.91%, Test F1:  2.03%
consistency_top_sec: 22.43%,  consistency_sec_conn:  7.70%, consistency_top_sec_conn:  7.70%
              precision    recall  f1-score   support

    Temporal     0.5000    0.2571    0.3396        70
 Contingency     0.3883    0.4124    0.4000        97
  Comparison     0.5246    0.2936    0.3765       109
   Expansion     0.6606    0.8000    0.7236       360

    accuracy                         0.5943       636
   macro avg     0.5184    0.4408    0.4599       636
weighted avg     0.5781    0.5943    0.5725       636

                             precision    recall  f1-score   support

      Temporal.Asynchronous     0.4872    0.2714    0.3486        70
         Temporal.Synchrony     0.3650    0.5155    0.4274        97
          Contingency.Cause     0.0290    0.4000    0.0541         5
Contingency.Pragmatic cause     0.0000    0.0000    0.0000       104
        Comparison.Contrast     0.6958    0.4841    0.5709       345
      Comparison.Concession     0.7000    0.4667    0.5600        15

                  micro avg     0.4949    0.3852    0.4332       636
                  macro avg     0.3795    0.3563    0.3268       636
               weighted avg     0.5035    0.3852    0.4269       636

Epoch [7/30]
top-down:TOP: Iter:   2400,  Train Loss: 3.2e+01,  Train Acc: 68.75%,Val Loss:   5.8,  Val Acc: 60.86%, Val F1: 48.95% Time: 34.14000678062439 
top-down:SEC: Iter:   2400,  Train Loss: 3.2e+01,  Train Acc: 56.25%,Val Loss:   5.8,  Val Acc: 46.87%, Val F1: 29.34% Time: 34.14000678062439 
top-down:CONN: Iter:   2400,  Train Loss: 3.2e+01,  Train Acc: 31.25%,Val Loss:   5.8,  Val Acc: 25.84%, Val F1:  5.79% Time: 34.14000678062439 
 
 
top-down:TOP: Iter:   2500,  Train Loss: 2.8e+01,  Train Acc: 81.25%,Val Loss:   5.8,  Val Acc: 62.06%, Val F1: 50.08% Time: 112.71922588348389 
top-down:SEC: Iter:   2500,  Train Loss: 2.8e+01,  Train Acc: 68.75%,Val Loss:   5.8,  Val Acc: 46.78%, Val F1: 28.24% Time: 112.71922588348389 
top-down:CONN: Iter:   2500,  Train Loss: 2.8e+01,  Train Acc: 68.75%,Val Loss:   5.8,  Val Acc: 26.52%, Val F1:  6.26% Time: 112.71922588348389 
 
 
top-down:TOP: Iter:   2600,  Train Loss: 3.3e+01,  Train Acc: 81.25%,Val Loss:   5.9,  Val Acc: 61.63%, Val F1: 50.57% Time: 191.34441709518433 
top-down:SEC: Iter:   2600,  Train Loss: 3.3e+01,  Train Acc: 75.00%,Val Loss:   5.9,  Val Acc: 47.73%, Val F1: 29.07% Time: 191.34441709518433 
top-down:CONN: Iter:   2600,  Train Loss: 3.3e+01,  Train Acc: 28.12%,Val Loss:   5.9,  Val Acc: 27.30%, Val F1:  6.31% Time: 191.34441709518433 
 
 
top-down:TOP: Iter:   2700,  Train Loss: 3.4e+01,  Train Acc: 78.12%,Val Loss:   5.8,  Val Acc: 60.77%, Val F1: 50.54% Time: 270.2008500099182 
top-down:SEC: Iter:   2700,  Train Loss: 3.4e+01,  Train Acc: 65.62%,Val Loss:   5.8,  Val Acc: 48.24%, Val F1: 29.61% Time: 270.2008500099182 
top-down:CONN: Iter:   2700,  Train Loss: 3.4e+01,  Train Acc: 34.38%,Val Loss:   5.8,  Val Acc: 26.61%, Val F1:  6.78% Time: 270.2008500099182 
 
 
Train time usage: 310.34684705734253
Test time usage: 1.1020026206970215
TOP: Test Loss:   6.5,  Test Acc: 59.12%, Test F1: 46.90%
SEC: Test Loss:   6.5,  Test Acc: 39.94%, Test F1: 24.38%
CONN: Test Loss:   6.5,  Test Acc: 19.65%, Test F1:  1.43%
consistency_top_sec: 23.58%,  consistency_sec_conn:  7.22%, consistency_top_sec_conn:  7.22%
              precision    recall  f1-score   support

    Temporal     0.4878    0.2857    0.3604        70
 Contingency     0.4016    0.5052    0.4475        97
  Comparison     0.5273    0.2661    0.3537       109
   Expansion     0.6651    0.7722    0.7147       360

    accuracy                         0.5912       636
   macro avg     0.5204    0.4573    0.4690       636
weighted avg     0.5818    0.5912    0.5730       636

                             precision    recall  f1-score   support

      Temporal.Asynchronous     0.5098    0.3714    0.4298        70
         Temporal.Synchrony     0.3451    0.5052    0.4100        97
          Contingency.Cause     0.0192    0.2000    0.0351         5
Contingency.Pragmatic cause     0.0000    0.0000    0.0000       104
        Comparison.Contrast     0.6798    0.4986    0.5753       345
      Comparison.Concession     0.6667    0.4000    0.5000        15

                  micro avg     0.5010    0.3994    0.4444       636
                  macro avg     0.3701    0.3292    0.3250       636
               weighted avg     0.4934    0.3994    0.4340       636

Epoch [8/30]
top-down:TOP: Iter:   2800,  Train Loss: 3.1e+01,  Train Acc: 87.50%,Val Loss:   6.0,  Val Acc: 60.86%, Val F1: 50.29% Time: 39.52947235107422 
top-down:SEC: Iter:   2800,  Train Loss: 3.1e+01,  Train Acc: 75.00%,Val Loss:   6.0,  Val Acc: 47.21%, Val F1: 29.24% Time: 39.52947235107422 
top-down:CONN: Iter:   2800,  Train Loss: 3.1e+01,  Train Acc: 62.50%,Val Loss:   6.0,  Val Acc: 27.38%, Val F1:  6.46% Time: 39.52947235107422 
 
 
top-down:TOP: Iter:   2900,  Train Loss: 2.6e+01,  Train Acc: 87.50%,Val Loss:   6.2,  Val Acc: 60.94%, Val F1: 49.55% Time: 118.2278344631195 
top-down:SEC: Iter:   2900,  Train Loss: 2.6e+01,  Train Acc: 81.25%,Val Loss:   6.2,  Val Acc: 46.35%, Val F1: 29.10% Time: 118.2278344631195 
top-down:CONN: Iter:   2900,  Train Loss: 2.6e+01,  Train Acc: 43.75%,Val Loss:   6.2,  Val Acc: 26.70%, Val F1:  6.54% Time: 118.2278344631195 
 
 
top-down:TOP: Iter:   3000,  Train Loss: 3e+01,  Train Acc: 90.62%,Val Loss:   6.1,  Val Acc: 61.55%, Val F1: 48.89% Time: 197.01435446739197 
top-down:SEC: Iter:   3000,  Train Loss: 3e+01,  Train Acc: 84.38%,Val Loss:   6.1,  Val Acc: 45.92%, Val F1: 27.97% Time: 197.01435446739197 
top-down:CONN: Iter:   3000,  Train Loss: 3e+01,  Train Acc: 53.12%,Val Loss:   6.1,  Val Acc: 26.09%, Val F1:  6.76% Time: 197.01435446739197 
 
 
top-down:TOP: Iter:   3100,  Train Loss: 2.7e+01,  Train Acc: 75.00%,Val Loss:   6.0,  Val Acc: 62.23%, Val F1: 51.79% Time: 275.5578281879425 
top-down:SEC: Iter:   3100,  Train Loss: 2.7e+01,  Train Acc: 62.50%,Val Loss:   6.0,  Val Acc: 46.70%, Val F1: 28.69% Time: 275.5578281879425 
top-down:CONN: Iter:   3100,  Train Loss: 2.7e+01,  Train Acc: 37.50%,Val Loss:   6.0,  Val Acc: 26.95%, Val F1:  6.97% Time: 275.5578281879425 
 
 
Train time usage: 310.41636061668396
Test time usage: 1.0867929458618164
TOP: Test Loss:   6.4,  Test Acc: 57.86%, Test F1: 42.85%
SEC: Test Loss:   6.4,  Test Acc: 40.88%, Test F1: 20.72%
CONN: Test Loss:   6.4,  Test Acc: 24.69%, Test F1:  1.80%
consistency_top_sec: 23.87%,  consistency_sec_conn:  9.05%, consistency_top_sec_conn:  9.05%
              precision    recall  f1-score   support

    Temporal     0.5312    0.2429    0.3333        70
 Contingency     0.4235    0.3711    0.3956        97
  Comparison     0.3833    0.2110    0.2722       109
   Expansion     0.6362    0.8111    0.7131       360

    accuracy                         0.5786       636
   macro avg     0.4936    0.4090    0.4285       636
weighted avg     0.5489    0.5786    0.5473       636

                             precision    recall  f1-score   support

      Temporal.Asynchronous     0.5122    0.3000    0.3784        70
         Temporal.Synchrony     0.3824    0.4021    0.3920        97
          Contingency.Cause     0.0204    0.2000    0.0370         5
Contingency.Pragmatic cause     0.0000    0.0000    0.0000       104
        Comparison.Contrast     0.6488    0.5623    0.6025       345
      Comparison.Concession     0.7143    0.3333    0.4545        15

                  micro avg     0.5221    0.4088    0.4586       636
                  macro avg     0.3797    0.2996    0.3107       636
               weighted avg     0.4837    0.4088    0.4393       636

Epoch [9/30]
top-down:TOP: Iter:   3200,  Train Loss: 3e+01,  Train Acc: 93.75%,Val Loss:   6.2,  Val Acc: 60.94%, Val F1: 51.45% Time: 44.82896685600281 
top-down:SEC: Iter:   3200,  Train Loss: 3e+01,  Train Acc: 93.75%,Val Loss:   6.2,  Val Acc: 47.55%, Val F1: 29.71% Time: 44.82896685600281 
top-down:CONN: Iter:   3200,  Train Loss: 3e+01,  Train Acc: 56.25%,Val Loss:   6.2,  Val Acc: 27.98%, Val F1:  6.70% Time: 44.82896685600281 
 
 
top-down:TOP: Iter:   3300,  Train Loss: 3e+01,  Train Acc: 100.00%,Val Loss:   6.1,  Val Acc: 61.46%, Val F1: 51.34% Time: 123.40112161636353 
top-down:SEC: Iter:   3300,  Train Loss: 3e+01,  Train Acc: 84.38%,Val Loss:   6.1,  Val Acc: 47.04%, Val F1: 30.13% Time: 123.40112161636353 
top-down:CONN: Iter:   3300,  Train Loss: 3e+01,  Train Acc: 71.88%,Val Loss:   6.1,  Val Acc: 27.12%, Val F1:  6.61% Time: 123.40112161636353 
 
 
top-down:TOP: Iter:   3400,  Train Loss: 2.5e+01,  Train Acc: 81.25%,Val Loss:   6.2,  Val Acc: 62.23%, Val F1: 52.44% Time: 202.24361753463745 
top-down:SEC: Iter:   3400,  Train Loss: 2.5e+01,  Train Acc: 75.00%,Val Loss:   6.2,  Val Acc: 46.61%, Val F1: 29.89% Time: 202.24361753463745 
top-down:CONN: Iter:   3400,  Train Loss: 2.5e+01,  Train Acc: 46.88%,Val Loss:   6.2,  Val Acc: 26.95%, Val F1:  7.09% Time: 202.24361753463745 
 
 
top-down:TOP: Iter:   3500,  Train Loss: 3.3e+01,  Train Acc: 90.62%,Val Loss:   6.3,  Val Acc: 61.72%, Val F1: 49.04% Time: 280.7124800682068 
top-down:SEC: Iter:   3500,  Train Loss: 3.3e+01,  Train Acc: 84.38%,Val Loss:   6.3,  Val Acc: 46.44%, Val F1: 28.79% Time: 280.7124800682068 
top-down:CONN: Iter:   3500,  Train Loss: 3.3e+01,  Train Acc: 43.75%,Val Loss:   6.3,  Val Acc: 27.12%, Val F1:  7.05% Time: 280.7124800682068 
 
 
Train time usage: 310.26962757110596
Test time usage: 1.1028969287872314
TOP: Test Loss:   7.4,  Test Acc: 57.08%, Test F1: 44.13%
SEC: Test Loss:   7.4,  Test Acc: 38.68%, Test F1: 20.41%
CONN: Test Loss:   7.4,  Test Acc: 18.08%, Test F1:  1.28%
consistency_top_sec: 22.62%,  consistency_sec_conn:  7.03%, consistency_top_sec_conn:  6.93%
              precision    recall  f1-score   support

    Temporal     0.4423    0.3286    0.3770        70
 Contingency     0.3504    0.4227    0.3832        97
  Comparison     0.4364    0.2202    0.2927       109
   Expansion     0.6675    0.7639    0.7124       360

    accuracy                         0.5708       636
   macro avg     0.4741    0.4338    0.4413       636
weighted avg     0.5547    0.5708    0.5534       636

                             precision    recall  f1-score   support

      Temporal.Asynchronous     0.5091    0.4000    0.4480        70
         Temporal.Synchrony     0.3333    0.4536    0.3843        97
          Contingency.Cause     0.0200    0.2000    0.0364         5
Contingency.Pragmatic cause     0.0000    0.0000    0.0000       104
        Comparison.Contrast     0.6829    0.4870    0.5685       345
      Comparison.Concession     0.5000    0.3333    0.4000        15

                  micro avg     0.4990    0.3868    0.4358       636
                  macro avg     0.3409    0.3123    0.3062       636
               weighted avg     0.4893    0.3868    0.4260       636

Epoch [10/30]
top-down:TOP: Iter:   3600,  Train Loss: 2.5e+01,  Train Acc: 87.50%,Val Loss:   6.4,  Val Acc: 60.34%, Val F1: 49.84% Time: 50.168209075927734 
top-down:SEC: Iter:   3600,  Train Loss: 2.5e+01,  Train Acc: 75.00%,Val Loss:   6.4,  Val Acc: 46.78%, Val F1: 28.57% Time: 50.168209075927734 
top-down:CONN: Iter:   3600,  Train Loss: 2.5e+01,  Train Acc: 50.00%,Val Loss:   6.4,  Val Acc: 26.44%, Val F1:  6.10% Time: 50.168209075927734 
 
 
top-down:TOP: Iter:   3700,  Train Loss: 2.9e+01,  Train Acc: 87.50%,Val Loss:   6.6,  Val Acc: 61.55%, Val F1: 51.01% Time: 128.61236190795898 
top-down:SEC: Iter:   3700,  Train Loss: 2.9e+01,  Train Acc: 75.00%,Val Loss:   6.6,  Val Acc: 45.67%, Val F1: 29.51% Time: 128.61236190795898 
top-down:CONN: Iter:   3700,  Train Loss: 2.9e+01,  Train Acc: 50.00%,Val Loss:   6.6,  Val Acc: 26.01%, Val F1:  6.77% Time: 128.61236190795898 
 
 
top-down:TOP: Iter:   3800,  Train Loss: 2.7e+01,  Train Acc: 84.38%,Val Loss:   6.4,  Val Acc: 62.32%, Val F1: 51.68% Time: 207.0529329776764 
top-down:SEC: Iter:   3800,  Train Loss: 2.7e+01,  Train Acc: 71.88%,Val Loss:   6.4,  Val Acc: 46.61%, Val F1: 28.44% Time: 207.0529329776764 
top-down:CONN: Iter:   3800,  Train Loss: 2.7e+01,  Train Acc: 37.50%,Val Loss:   6.4,  Val Acc: 26.70%, Val F1:  6.78% Time: 207.0529329776764 
 
 
top-down:TOP: Iter:   3900,  Train Loss: 3e+01,  Train Acc: 90.62%,Val Loss:   6.6,  Val Acc: 61.97%, Val F1: 49.87% Time: 285.5992364883423 
top-down:SEC: Iter:   3900,  Train Loss: 3e+01,  Train Acc: 84.38%,Val Loss:   6.6,  Val Acc: 45.32%, Val F1: 28.86% Time: 285.5992364883423 
top-down:CONN: Iter:   3900,  Train Loss: 3e+01,  Train Acc: 53.12%,Val Loss:   6.6,  Val Acc: 27.12%, Val F1:  6.85% Time: 285.5992364883423 
 
 
Train time usage: 309.4469475746155
Test time usage: 1.0973167419433594
TOP: Test Loss:   7.3,  Test Acc: 58.96%, Test F1: 45.65%
SEC: Test Loss:   7.3,  Test Acc: 39.62%, Test F1: 20.95%
CONN: Test Loss:   7.3,  Test Acc: 24.06%, Test F1:  1.55%
consistency_top_sec: 23.77%,  consistency_sec_conn:  8.57%, consistency_top_sec_conn:  8.47%
              precision    recall  f1-score   support

    Temporal     0.5152    0.2429    0.3301        70
 Contingency     0.3814    0.4639    0.4186        97
  Comparison     0.4627    0.2844    0.3523       109
   Expansion     0.6746    0.7833    0.7249       360

    accuracy                         0.5896       636
   macro avg     0.5085    0.4436    0.4565       636
weighted avg     0.5760    0.5896    0.5709       636

                             precision    recall  f1-score   support

      Temporal.Asynchronous     0.5135    0.2714    0.3551        70
         Temporal.Synchrony     0.3507    0.4845    0.4069        97
          Contingency.Cause     0.0312    0.4000    0.0580         5
Contingency.Pragmatic cause     0.0000    0.0000    0.0000       104
        Comparison.Contrast     0.6768    0.5159    0.5855       345
      Comparison.Concession     0.6000    0.4000    0.4800        15

                  micro avg     0.4961    0.3962    0.4406       636
                  macro avg     0.3621    0.3453    0.3143       636
               weighted avg     0.4915    0.3962    0.4305       636

Epoch [11/30]
top-down:TOP: Iter:   4000,  Train Loss: 3.2e+01,  Train Acc: 96.88%,Val Loss:   6.8,  Val Acc: 61.12%, Val F1: 50.11% Time: 55.685208320617676 
top-down:SEC: Iter:   4000,  Train Loss: 3.2e+01,  Train Acc: 68.75%,Val Loss:   6.8,  Val Acc: 46.35%, Val F1: 29.76% Time: 55.685208320617676 
top-down:CONN: Iter:   4000,  Train Loss: 3.2e+01,  Train Acc: 53.12%,Val Loss:   6.8,  Val Acc: 25.92%, Val F1:  6.63% Time: 55.685208320617676 
 
 
top-down:TOP: Iter:   4100,  Train Loss: 3.2e+01,  Train Acc: 87.50%,Val Loss:   6.8,  Val Acc: 61.89%, Val F1: 49.61% Time: 134.28855204582214 
top-down:SEC: Iter:   4100,  Train Loss: 3.2e+01,  Train Acc: 62.50%,Val Loss:   6.8,  Val Acc: 45.58%, Val F1: 28.54% Time: 134.28855204582214 
top-down:CONN: Iter:   4100,  Train Loss: 3.2e+01,  Train Acc: 34.38%,Val Loss:   6.8,  Val Acc: 25.92%, Val F1:  6.50% Time: 134.28855204582214 
 
 
top-down:TOP: Iter:   4200,  Train Loss: 2.9e+01,  Train Acc: 90.62%,Val Loss:   6.8,  Val Acc: 60.52%, Val F1: 49.86% Time: 212.99892902374268 
top-down:SEC: Iter:   4200,  Train Loss: 2.9e+01,  Train Acc: 68.75%,Val Loss:   6.8,  Val Acc: 44.81%, Val F1: 28.75% Time: 212.99892902374268 
top-down:CONN: Iter:   4200,  Train Loss: 2.9e+01,  Train Acc: 40.62%,Val Loss:   6.8,  Val Acc: 25.32%, Val F1:  6.86% Time: 212.99892902374268 
 
 
top-down:TOP: Iter:   4300,  Train Loss: 2.6e+01,  Train Acc: 90.62%,Val Loss:   6.7,  Val Acc: 60.77%, Val F1: 51.14% Time: 291.5288550853729 
top-down:SEC: Iter:   4300,  Train Loss: 2.6e+01,  Train Acc: 84.38%,Val Loss:   6.7,  Val Acc: 45.58%, Val F1: 27.04% Time: 291.5288550853729 
top-down:CONN: Iter:   4300,  Train Loss: 2.6e+01,  Train Acc: 37.50%,Val Loss:   6.7,  Val Acc: 25.92%, Val F1:  6.59% Time: 291.5288550853729 
 
 
Train time usage: 310.3129003047943
Test time usage: 1.1107115745544434
TOP: Test Loss:   7.8,  Test Acc: 57.55%, Test F1: 45.46%
SEC: Test Loss:   7.8,  Test Acc: 37.42%, Test F1: 17.07%
CONN: Test Loss:   7.8,  Test Acc: 20.91%, Test F1:  1.33%
consistency_top_sec: 22.43%,  consistency_sec_conn:  7.60%, consistency_top_sec_conn:  7.60%
              precision    recall  f1-score   support

    Temporal     0.5000    0.3429    0.4068        70
 Contingency     0.3769    0.5052    0.4317        97
  Comparison     0.4151    0.2018    0.2716       109
   Expansion     0.6691    0.7528    0.7085       360

    accuracy                         0.5755       636
   macro avg     0.4903    0.4507    0.4546       636
weighted avg     0.5624    0.5755    0.5582       636

                             precision    recall  f1-score   support

      Temporal.Asynchronous     0.4565    0.3000    0.3621        70
         Temporal.Synchrony     0.3448    0.5155    0.4132        97
          Contingency.Cause     0.0200    0.2000    0.0364         5
Contingency.Pragmatic cause     0.0000    0.0000    0.0000       104
        Comparison.Contrast     0.6559    0.4696    0.5473       345
      Comparison.Concession     0.5000    0.2667    0.3478        15

                  micro avg     0.4798    0.3742    0.4205       636
                  macro avg     0.3295    0.2919    0.2845       636
               weighted avg     0.4706    0.3742    0.4082       636

Epoch [12/30]
top-down:TOP: Iter:   4400,  Train Loss: 3.1e+01,  Train Acc: 93.75%,Val Loss:   6.9,  Val Acc: 60.17%, Val F1: 50.37% Time: 61.15361952781677 
top-down:SEC: Iter:   4400,  Train Loss: 3.1e+01,  Train Acc: 87.50%,Val Loss:   6.9,  Val Acc: 43.61%, Val F1: 27.20% Time: 61.15361952781677 
top-down:CONN: Iter:   4400,  Train Loss: 3.1e+01,  Train Acc: 53.12%,Val Loss:   6.9,  Val Acc: 26.09%, Val F1:  7.30% Time: 61.15361952781677 
 
 
top-down:TOP: Iter:   4500,  Train Loss: 2.9e+01,  Train Acc: 96.88%,Val Loss:   6.9,  Val Acc: 60.77%, Val F1: 49.93% Time: 139.9130458831787 
top-down:SEC: Iter:   4500,  Train Loss: 2.9e+01,  Train Acc: 87.50%,Val Loss:   6.9,  Val Acc: 44.81%, Val F1: 27.84% Time: 139.9130458831787 
top-down:CONN: Iter:   4500,  Train Loss: 2.9e+01,  Train Acc: 37.50%,Val Loss:   6.9,  Val Acc: 25.67%, Val F1:  6.56% Time: 139.9130458831787 
 
 
top-down:TOP: Iter:   4600,  Train Loss: 2.7e+01,  Train Acc: 90.62%,Val Loss:   6.9,  Val Acc: 61.55%, Val F1: 48.37% Time: 218.47043752670288 
top-down:SEC: Iter:   4600,  Train Loss: 2.7e+01,  Train Acc: 84.38%,Val Loss:   6.9,  Val Acc: 44.98%, Val F1: 26.85% Time: 218.47043752670288 
top-down:CONN: Iter:   4600,  Train Loss: 2.7e+01,  Train Acc: 50.00%,Val Loss:   6.9,  Val Acc: 26.87%, Val F1:  7.37% Time: 218.47043752670288 
 
 
top-down:TOP: Iter:   4700,  Train Loss: 3e+01,  Train Acc: 93.75%,Val Loss:   7.0,  Val Acc: 60.17%, Val F1: 48.12% Time: 297.01158595085144 
top-down:SEC: Iter:   4700,  Train Loss: 3e+01,  Train Acc: 78.12%,Val Loss:   7.0,  Val Acc: 43.86%, Val F1: 27.56% Time: 297.01158595085144 
top-down:CONN: Iter:   4700,  Train Loss: 3e+01,  Train Acc: 43.75%,Val Loss:   7.0,  Val Acc: 26.35%, Val F1:  6.95% Time: 297.01158595085144 
 
 
Train time usage: 310.3624858856201
Test time usage: 1.0824801921844482
TOP: Test Loss:   8.1,  Test Acc: 56.60%, Test F1: 44.35%
SEC: Test Loss:   8.1,  Test Acc: 38.99%, Test F1: 22.99%
CONN: Test Loss:   8.1,  Test Acc: 18.87%, Test F1:  1.18%
consistency_top_sec: 23.20%,  consistency_sec_conn:  6.83%, consistency_top_sec_conn:  6.83%
              precision    recall  f1-score   support

    Temporal     0.4889    0.3143    0.3826        70
 Contingency     0.3603    0.5052    0.4206        97
  Comparison     0.4000    0.2018    0.2683       109
   Expansion     0.6675    0.7417    0.7026       360

    accuracy                         0.5660       636
   macro avg     0.4792    0.4407    0.4435       636
weighted avg     0.5551    0.5660    0.5500       636

                             precision    recall  f1-score   support

      Temporal.Asynchronous     0.4681    0.3143    0.3761        70
         Temporal.Synchrony     0.3542    0.5258    0.4232        97
          Contingency.Cause     0.0192    0.2000    0.0351         5
Contingency.Pragmatic cause     0.0000    0.0000    0.0000       104
        Comparison.Contrast     0.6815    0.4899    0.5700       345
      Comparison.Concession     0.6250    0.3333    0.4348        15

                  micro avg     0.4970    0.3899    0.4370       636
                  macro avg     0.3580    0.3105    0.3065       636
               weighted avg     0.4901    0.3899    0.4257       636

Epoch [13/30]
top-down:TOP: Iter:   4800,  Train Loss: 2.5e+01,  Train Acc: 93.75%,Val Loss:   7.0,  Val Acc: 60.17%, Val F1: 49.63% Time: 66.29933428764343 
top-down:SEC: Iter:   4800,  Train Loss: 2.5e+01,  Train Acc: 90.62%,Val Loss:   7.0,  Val Acc: 44.55%, Val F1: 28.08% Time: 66.29933428764343 
top-down:CONN: Iter:   4800,  Train Loss: 2.5e+01,  Train Acc: 53.12%,Val Loss:   7.0,  Val Acc: 26.95%, Val F1:  7.19% Time: 66.29933428764343 
 
 
top-down:TOP: Iter:   4900,  Train Loss: 2.5e+01,  Train Acc: 93.75%,Val Loss:   7.2,  Val Acc: 60.60%, Val F1: 49.62% Time: 145.2247941493988 
top-down:SEC: Iter:   4900,  Train Loss: 2.5e+01,  Train Acc: 84.38%,Val Loss:   7.2,  Val Acc: 45.32%, Val F1: 28.84% Time: 145.2247941493988 
top-down:CONN: Iter:   4900,  Train Loss: 2.5e+01,  Train Acc: 53.12%,Val Loss:   7.2,  Val Acc: 26.35%, Val F1:  7.06% Time: 145.2247941493988 
 
 
top-down:TOP: Iter:   5000,  Train Loss: 2.8e+01,  Train Acc: 100.00%,Val Loss:   7.2,  Val Acc: 60.60%, Val F1: 48.83% Time: 224.0014123916626 
top-down:SEC: Iter:   5000,  Train Loss: 2.8e+01,  Train Acc: 90.62%,Val Loss:   7.2,  Val Acc: 44.64%, Val F1: 27.65% Time: 224.0014123916626 
top-down:CONN: Iter:   5000,  Train Loss: 2.8e+01,  Train Acc: 46.88%,Val Loss:   7.2,  Val Acc: 25.84%, Val F1:  7.33% Time: 224.0014123916626 
 
 
top-down:TOP: Iter:   5100,  Train Loss: 3.1e+01,  Train Acc: 100.00%,Val Loss:   7.2,  Val Acc: 60.86%, Val F1: 49.63% Time: 302.8294413089752 
top-down:SEC: Iter:   5100,  Train Loss: 3.1e+01,  Train Acc: 93.75%,Val Loss:   7.2,  Val Acc: 44.55%, Val F1: 28.40% Time: 302.8294413089752 
top-down:CONN: Iter:   5100,  Train Loss: 3.1e+01,  Train Acc: 50.00%,Val Loss:   7.2,  Val Acc: 25.67%, Val F1:  6.94% Time: 302.8294413089752 
 
 
Train time usage: 310.63778162002563
Test time usage: 1.0822553634643555
TOP: Test Loss:   8.1,  Test Acc: 59.75%, Test F1: 47.58%
SEC: Test Loss:   8.1,  Test Acc: 37.42%, Test F1: 17.35%
CONN: Test Loss:   8.1,  Test Acc: 19.97%, Test F1:  1.33%
consistency_top_sec: 22.23%,  consistency_sec_conn:  7.31%, consistency_top_sec_conn:  7.31%
              precision    recall  f1-score   support

    Temporal     0.4694    0.3286    0.3866        70
 Contingency     0.4674    0.4433    0.4550        97
  Comparison     0.4478    0.2752    0.3409       109
   Expansion     0.6636    0.7889    0.7208       360

    accuracy                         0.5975       636
   macro avg     0.5120    0.4590    0.4758       636
weighted avg     0.5753    0.5975    0.5784       636

                             precision    recall  f1-score   support

      Temporal.Asynchronous     0.4615    0.3429    0.3934        70
         Temporal.Synchrony     0.4316    0.4227    0.4271        97
          Contingency.Cause     0.0147    0.2000    0.0274         5
Contingency.Pragmatic cause     0.0000    0.0000    0.0000       104
        Comparison.Contrast     0.6802    0.4870    0.5676       345
      Comparison.Concession     0.4000    0.2667    0.3200        15

                  micro avg     0.5042    0.3742    0.4296       636
                  macro avg     0.3313    0.2865    0.2892       636
               weighted avg     0.4951    0.3742    0.4241       636

Epoch [14/30]
top-down:TOP: Iter:   5200,  Train Loss: 3e+01,  Train Acc: 90.62%,Val Loss:   7.2,  Val Acc: 61.89%, Val F1: 50.28% Time: 71.98564863204956 
top-down:SEC: Iter:   5200,  Train Loss: 3e+01,  Train Acc: 90.62%,Val Loss:   7.2,  Val Acc: 44.81%, Val F1: 27.77% Time: 71.98564863204956 
top-down:CONN: Iter:   5200,  Train Loss: 3e+01,  Train Acc: 59.38%,Val Loss:   7.2,  Val Acc: 27.47%, Val F1:  7.57% Time: 71.98564863204956 
 
 
top-down:TOP: Iter:   5300,  Train Loss: 2.8e+01,  Train Acc: 96.88%,Val Loss:   7.2,  Val Acc: 60.94%, Val F1: 50.41% Time: 150.868243932724 
top-down:SEC: Iter:   5300,  Train Loss: 2.8e+01,  Train Acc: 90.62%,Val Loss:   7.2,  Val Acc: 45.24%, Val F1: 29.11% Time: 150.868243932724 
top-down:CONN: Iter:   5300,  Train Loss: 2.8e+01,  Train Acc: 53.12%,Val Loss:   7.2,  Val Acc: 26.70%, Val F1:  7.28% Time: 150.868243932724 
 
 
top-down:TOP: Iter:   5400,  Train Loss: 3.2e+01,  Train Acc: 93.75%,Val Loss:   7.4,  Val Acc: 60.60%, Val F1: 49.54% Time: 229.863018989563 
top-down:SEC: Iter:   5400,  Train Loss: 3.2e+01,  Train Acc: 81.25%,Val Loss:   7.4,  Val Acc: 43.78%, Val F1: 28.56% Time: 229.863018989563 
top-down:CONN: Iter:   5400,  Train Loss: 3.2e+01,  Train Acc: 59.38%,Val Loss:   7.4,  Val Acc: 25.49%, Val F1:  7.51% Time: 229.863018989563 
 
 
top-down:TOP: Iter:   5500,  Train Loss: 3.5e+01,  Train Acc: 96.88%,Val Loss:   7.2,  Val Acc: 61.29%, Val F1: 50.10% Time: 308.9673397541046 
top-down:SEC: Iter:   5500,  Train Loss: 3.5e+01,  Train Acc: 87.50%,Val Loss:   7.2,  Val Acc: 44.89%, Val F1: 28.24% Time: 308.9673397541046 
top-down:CONN: Iter:   5500,  Train Loss: 3.5e+01,  Train Acc: 40.62%,Val Loss:   7.2,  Val Acc: 26.87%, Val F1:  7.51% Time: 308.9673397541046 
 
 
Train time usage: 311.6157922744751
Test time usage: 1.112227201461792
TOP: Test Loss:   8.3,  Test Acc: 58.96%, Test F1: 46.07%
SEC: Test Loss:   8.3,  Test Acc: 34.75%, Test F1: 17.50%
CONN: Test Loss:   8.3,  Test Acc: 20.60%, Test F1:  1.31%
consistency_top_sec: 20.60%,  consistency_sec_conn:  6.45%, consistency_top_sec_conn:  6.45%
              precision    recall  f1-score   support

    Temporal     0.4200    0.3000    0.3500        70
 Contingency     0.4396    0.4124    0.4255        97
  Comparison     0.5370    0.2661    0.3558       109
   Expansion     0.6463    0.7917    0.7116       360

    accuracy                         0.5896       636
   macro avg     0.5107    0.4425    0.4607       636
weighted avg     0.5711    0.5896    0.5672       636

                             precision    recall  f1-score   support

      Temporal.Asynchronous     0.4423    0.3286    0.3770        70
         Temporal.Synchrony     0.4316    0.4227    0.4271        97
          Contingency.Cause     0.0179    0.2000    0.0328         5
Contingency.Pragmatic cause     0.0000    0.0000    0.0000       104
        Comparison.Contrast     0.6652    0.4377    0.5280       345
      Comparison.Concession     0.4545    0.3333    0.3846        15

                  micro avg     0.5011    0.3475    0.4104       636
                  macro avg     0.3352    0.2870    0.2916       636
               weighted avg     0.4862    0.3475    0.4024       636

Epoch [15/30]
top-down:TOP: Iter:   5600,  Train Loss: 2.8e+01,  Train Acc: 93.75%,Val Loss:   7.4,  Val Acc: 61.20%, Val F1: 50.14% Time: 77.37430572509766 
top-down:SEC: Iter:   5600,  Train Loss: 2.8e+01,  Train Acc: 84.38%,Val Loss:   7.4,  Val Acc: 44.72%, Val F1: 28.12% Time: 77.37430572509766 
top-down:CONN: Iter:   5600,  Train Loss: 2.8e+01,  Train Acc: 59.38%,Val Loss:   7.4,  Val Acc: 26.61%, Val F1:  7.82% Time: 77.37430572509766 
 
 
top-down:TOP: Iter:   5700,  Train Loss: 2.7e+01,  Train Acc: 93.75%,Val Loss:   7.2,  Val Acc: 61.89%, Val F1: 50.45% Time: 156.31666016578674 
top-down:SEC: Iter:   5700,  Train Loss: 2.7e+01,  Train Acc: 84.38%,Val Loss:   7.2,  Val Acc: 45.41%, Val F1: 27.63% Time: 156.31666016578674 
top-down:CONN: Iter:   5700,  Train Loss: 2.7e+01,  Train Acc: 46.88%,Val Loss:   7.2,  Val Acc: 26.35%, Val F1:  7.16% Time: 156.31666016578674 
 
 
top-down:TOP: Iter:   5800,  Train Loss: 2.3e+01,  Train Acc: 90.62%,Val Loss:   7.2,  Val Acc: 61.97%, Val F1: 49.40% Time: 235.08505177497864 
top-down:SEC: Iter:   5800,  Train Loss: 2.3e+01,  Train Acc: 81.25%,Val Loss:   7.2,  Val Acc: 45.84%, Val F1: 26.48% Time: 235.08505177497864 
top-down:CONN: Iter:   5800,  Train Loss: 2.3e+01,  Train Acc: 59.38%,Val Loss:   7.2,  Val Acc: 26.44%, Val F1:  7.53% Time: 235.08505177497864 
 
 
Train time usage: 309.22804737091064
Test time usage: 1.1112003326416016
TOP: Test Loss:   8.6,  Test Acc: 57.55%, Test F1: 44.10%
SEC: Test Loss:   8.6,  Test Acc: 39.31%, Test F1: 18.07%
CONN: Test Loss:   8.6,  Test Acc: 21.38%, Test F1:  1.30%
consistency_top_sec: 23.10%,  consistency_sec_conn:  7.89%, consistency_top_sec_conn:  7.80%
              precision    recall  f1-score   support

    Temporal     0.4091    0.2571    0.3158        70
 Contingency     0.3719    0.4639    0.4128        97
  Comparison     0.5098    0.2385    0.3250       109
   Expansion     0.6595    0.7694    0.7103       360

    accuracy                         0.5755       636
   macro avg     0.4876    0.4323    0.4410       636
weighted avg     0.5624    0.5755    0.5555       636

                             precision    recall  f1-score   support

      Temporal.Asynchronous     0.4375    0.3000    0.3559        70
         Temporal.Synchrony     0.3643    0.4845    0.4159        97
          Contingency.Cause     0.0392    0.4000    0.0714         5
Contingency.Pragmatic cause     0.0000    0.0000    0.0000       104
        Comparison.Contrast     0.6757    0.5072    0.5795       345
      Comparison.Concession     0.4545    0.3333    0.3846        15

                  micro avg     0.5020    0.3931    0.4409       636
                  macro avg     0.3285    0.3375    0.3012       636
               weighted avg     0.4813    0.3931    0.4266       636

Epoch [16/30]
top-down:TOP: Iter:   5900,  Train Loss: 2.8e+01,  Train Acc: 96.88%,Val Loss:   7.4,  Val Acc: 62.06%, Val F1: 51.44% Time: 5.731045484542847 
top-down:SEC: Iter:   5900,  Train Loss: 2.8e+01,  Train Acc: 90.62%,Val Loss:   7.4,  Val Acc: 45.49%, Val F1: 28.66% Time: 5.731045484542847 
top-down:CONN: Iter:   5900,  Train Loss: 2.8e+01,  Train Acc: 62.50%,Val Loss:   7.4,  Val Acc: 26.18%, Val F1:  7.65% Time: 5.731045484542847 
 
 
top-down:TOP: Iter:   6000,  Train Loss: 2.8e+01,  Train Acc: 96.88%,Val Loss:   7.5,  Val Acc: 61.12%, Val F1: 50.38% Time: 85.69471907615662 
top-down:SEC: Iter:   6000,  Train Loss: 2.8e+01,  Train Acc: 96.88%,Val Loss:   7.5,  Val Acc: 45.06%, Val F1: 28.30% Time: 85.69471907615662 
top-down:CONN: Iter:   6000,  Train Loss: 2.8e+01,  Train Acc: 43.75%,Val Loss:   7.5,  Val Acc: 25.84%, Val F1:  7.45% Time: 85.69471907615662 
 
 
top-down:TOP: Iter:   6100,  Train Loss: 2.3e+01,  Train Acc: 100.00%,Val Loss:   7.5,  Val Acc: 61.12%, Val F1: 51.38% Time: 173.60883259773254 
top-down:SEC: Iter:   6100,  Train Loss: 2.3e+01,  Train Acc: 87.50%,Val Loss:   7.5,  Val Acc: 45.41%, Val F1: 27.40% Time: 173.60883259773254 
top-down:CONN: Iter:   6100,  Train Loss: 2.3e+01,  Train Acc: 68.75%,Val Loss:   7.5,  Val Acc: 26.01%, Val F1:  7.35% Time: 173.60883259773254 
 
 
top-down:TOP: Iter:   6200,  Train Loss: 2.6e+01,  Train Acc: 96.88%,Val Loss:   7.4,  Val Acc: 61.46%, Val F1: 51.71% Time: 254.5683400630951 
top-down:SEC: Iter:   6200,  Train Loss: 2.6e+01,  Train Acc: 90.62%,Val Loss:   7.4,  Val Acc: 44.72%, Val F1: 27.09% Time: 254.5683400630951 
top-down:CONN: Iter:   6200,  Train Loss: 2.6e+01,  Train Acc: 65.62%,Val Loss:   7.4,  Val Acc: 26.09%, Val F1:  7.70% Time: 254.5683400630951 
 
 
Train time usage: 323.36803364753723
Test time usage: 1.1236615180969238
TOP: Test Loss:   8.3,  Test Acc: 58.49%, Test F1: 44.16%
SEC: Test Loss:   8.3,  Test Acc: 40.72%, Test F1: 17.96%
CONN: Test Loss:   8.3,  Test Acc: 24.06%, Test F1:  1.39%
consistency_top_sec: 24.06%,  consistency_sec_conn:  9.05%, consistency_top_sec_conn:  9.05%
              precision    recall  f1-score   support

    Temporal     0.4082    0.2857    0.3361        70
 Contingency     0.4091    0.3711    0.3892        97
  Comparison     0.5682    0.2294    0.3268       109
   Expansion     0.6396    0.8083    0.7141       360

    accuracy                         0.5849       636
   macro avg     0.5062    0.4236    0.4416       636
weighted avg     0.5667    0.5849    0.5566       636

                             precision    recall  f1-score   support

      Temporal.Asynchronous     0.4400    0.3143    0.3667        70
         Temporal.Synchrony     0.3918    0.3918    0.3918        97
          Contingency.Cause     0.0435    0.4000    0.0784         5
Contingency.Pragmatic cause     0.0000    0.0000    0.0000       104
        Comparison.Contrast     0.6748    0.5594    0.6117       345
      Comparison.Concession     0.5000    0.2667    0.3478        15

                  micro avg     0.5318    0.4072    0.4613       636
                  macro avg     0.3417    0.3220    0.2994       636
               weighted avg     0.4864    0.4072    0.4408       636

Epoch [17/30]
top-down:TOP: Iter:   6300,  Train Loss: 2.9e+01,  Train Acc: 100.00%,Val Loss:   7.5,  Val Acc: 61.63%, Val F1: 52.27% Time: 11.124945163726807 
top-down:SEC: Iter:   6300,  Train Loss: 2.9e+01,  Train Acc: 93.75%,Val Loss:   7.5,  Val Acc: 46.09%, Val F1: 28.70% Time: 11.124945163726807 
top-down:CONN: Iter:   6300,  Train Loss: 2.9e+01,  Train Acc: 62.50%,Val Loss:   7.5,  Val Acc: 26.70%, Val F1:  7.90% Time: 11.124945163726807 
 
 
top-down:TOP: Iter:   6400,  Train Loss: 2.4e+01,  Train Acc: 93.75%,Val Loss:   7.6,  Val Acc: 62.58%, Val F1: 51.34% Time: 90.14850950241089 
top-down:SEC: Iter:   6400,  Train Loss: 2.4e+01,  Train Acc: 84.38%,Val Loss:   7.6,  Val Acc: 45.58%, Val F1: 29.32% Time: 90.14850950241089 
top-down:CONN: Iter:   6400,  Train Loss: 2.4e+01,  Train Acc: 65.62%,Val Loss:   7.6,  Val Acc: 25.67%, Val F1:  7.86% Time: 90.14850950241089 
 
 
top-down:TOP: Iter:   6500,  Train Loss: 2.9e+01,  Train Acc: 96.88%,Val Loss:   7.6,  Val Acc: 61.20%, Val F1: 49.62% Time: 169.0897901058197 
top-down:SEC: Iter:   6500,  Train Loss: 2.9e+01,  Train Acc: 90.62%,Val Loss:   7.6,  Val Acc: 45.67%, Val F1: 29.04% Time: 169.0897901058197 
top-down:CONN: Iter:   6500,  Train Loss: 2.9e+01,  Train Acc: 56.25%,Val Loss:   7.6,  Val Acc: 25.67%, Val F1:  7.67% Time: 169.0897901058197 
 
 
top-down:TOP: Iter:   6600,  Train Loss: 2.6e+01,  Train Acc: 96.88%,Val Loss:   7.6,  Val Acc: 60.17%, Val F1: 50.97% Time: 247.7260286808014 
top-down:SEC: Iter:   6600,  Train Loss: 2.6e+01,  Train Acc: 90.62%,Val Loss:   7.6,  Val Acc: 44.81%, Val F1: 28.20% Time: 247.7260286808014 
top-down:CONN: Iter:   6600,  Train Loss: 2.6e+01,  Train Acc: 65.62%,Val Loss:   7.6,  Val Acc: 24.98%, Val F1:  7.26% Time: 247.7260286808014 
 
 
Train time usage: 311.0352737903595
Test time usage: 1.0813214778900146
TOP: Test Loss:   8.8,  Test Acc: 55.35%, Test F1: 45.34%
SEC: Test Loss:   8.8,  Test Acc: 37.26%, Test F1: 19.26%
CONN: Test Loss:   8.8,  Test Acc: 21.23%, Test F1:  1.17%
consistency_top_sec: 22.23%,  consistency_sec_conn:  7.22%, consistency_top_sec_conn:  7.03%
              precision    recall  f1-score   support

    Temporal     0.4894    0.3286    0.3932        70
 Contingency     0.3158    0.4948    0.3855        97
  Comparison     0.4918    0.2752    0.3529       109
   Expansion     0.6676    0.6972    0.6821       360

    accuracy                         0.5535       636
   macro avg     0.4911    0.4490    0.4534       636
weighted avg     0.5642    0.5535    0.5486       636

                             precision    recall  f1-score   support

      Temporal.Asynchronous     0.4800    0.3429    0.4000        70
         Temporal.Synchrony     0.2994    0.4845    0.3701        97
          Contingency.Cause     0.0167    0.2000    0.0308         5
Contingency.Pragmatic cause     0.0000    0.0000    0.0000       104
        Comparison.Contrast     0.6695    0.4638    0.5479       345
      Comparison.Concession     0.4545    0.3333    0.3846        15

                  micro avg     0.4584    0.3726    0.4111       636
                  macro avg     0.3200    0.3041    0.2889       636
               weighted avg     0.4725    0.3726    0.4070       636

Epoch [18/30]
top-down:TOP: Iter:   6700,  Train Loss: 2.3e+01,  Train Acc: 90.62%,Val Loss:   7.5,  Val Acc: 61.72%, Val F1: 49.85% Time: 16.563353300094604 
top-down:SEC: Iter:   6700,  Train Loss: 2.3e+01,  Train Acc: 87.50%,Val Loss:   7.5,  Val Acc: 44.98%, Val F1: 29.30% Time: 16.563353300094604 
top-down:CONN: Iter:   6700,  Train Loss: 2.3e+01,  Train Acc: 62.50%,Val Loss:   7.5,  Val Acc: 24.89%, Val F1:  7.42% Time: 16.563353300094604 
 
 
top-down:TOP: Iter:   6800,  Train Loss: 2.8e+01,  Train Acc: 93.75%,Val Loss:   7.6,  Val Acc: 61.03%, Val F1: 50.56% Time: 95.40777254104614 
top-down:SEC: Iter:   6800,  Train Loss: 2.8e+01,  Train Acc: 90.62%,Val Loss:   7.6,  Val Acc: 43.86%, Val F1: 27.87% Time: 95.40777254104614 
top-down:CONN: Iter:   6800,  Train Loss: 2.8e+01,  Train Acc: 71.88%,Val Loss:   7.6,  Val Acc: 24.72%, Val F1:  7.73% Time: 95.40777254104614 
 
 
top-down:TOP: Iter:   6900,  Train Loss: 2.1e+01,  Train Acc: 93.75%,Val Loss:   7.7,  Val Acc: 60.77%, Val F1: 51.34% Time: 174.32472324371338 
top-down:SEC: Iter:   6900,  Train Loss: 2.1e+01,  Train Acc: 87.50%,Val Loss:   7.7,  Val Acc: 44.72%, Val F1: 27.71% Time: 174.32472324371338 
top-down:CONN: Iter:   6900,  Train Loss: 2.1e+01,  Train Acc: 59.38%,Val Loss:   7.7,  Val Acc: 24.98%, Val F1:  7.59% Time: 174.32472324371338 
 
 
top-down:TOP: Iter:   7000,  Train Loss: 2.6e+01,  Train Acc: 93.75%,Val Loss:   7.9,  Val Acc: 61.46%, Val F1: 49.48% Time: 252.8172161579132 
top-down:SEC: Iter:   7000,  Train Loss: 2.6e+01,  Train Acc: 84.38%,Val Loss:   7.9,  Val Acc: 43.69%, Val F1: 28.29% Time: 252.8172161579132 
top-down:CONN: Iter:   7000,  Train Loss: 2.6e+01,  Train Acc: 50.00%,Val Loss:   7.9,  Val Acc: 24.55%, Val F1:  7.29% Time: 252.8172161579132 
 
 
Train time usage: 310.82844400405884
Test time usage: 1.0851116180419922
TOP: Test Loss:   8.8,  Test Acc: 58.96%, Test F1: 47.87%
SEC: Test Loss:   8.8,  Test Acc: 42.30%, Test F1: 19.23%
CONN: Test Loss:   8.8,  Test Acc: 19.34%, Test F1:  1.08%
consistency_top_sec: 24.93%,  consistency_sec_conn:  6.64%, consistency_top_sec_conn:  6.54%
              precision    recall  f1-score   support

    Temporal     0.4464    0.3571    0.3968        70
 Contingency     0.4144    0.4742    0.4423        97
  Comparison     0.5082    0.2844    0.3647       109
   Expansion     0.6691    0.7583    0.7109       360

    accuracy                         0.5896       636
   macro avg     0.5095    0.4685    0.4787       636
weighted avg     0.5782    0.5896    0.5761       636

                             precision    recall  f1-score   support

      Temporal.Asynchronous     0.4655    0.3857    0.4219        70
         Temporal.Synchrony     0.3680    0.4742    0.4144        97
          Contingency.Cause     0.0185    0.2000    0.0339         5
Contingency.Pragmatic cause     0.0000    0.0000    0.0000       104
        Comparison.Contrast     0.7037    0.5507    0.6179       345
      Comparison.Concession     0.6250    0.3333    0.4348        15

                  micro avg     0.5223    0.4230    0.4674       636
                  macro avg     0.3635    0.3240    0.3205       636
               weighted avg     0.5040    0.4230    0.4553       636

Epoch [19/30]
top-down:TOP: Iter:   7100,  Train Loss: 2.7e+01,  Train Acc: 96.88%,Val Loss:   7.7,  Val Acc: 60.86%, Val F1: 51.49% Time: 21.918066024780273 
top-down:SEC: Iter:   7100,  Train Loss: 2.7e+01,  Train Acc: 93.75%,Val Loss:   7.7,  Val Acc: 45.41%, Val F1: 29.04% Time: 21.918066024780273 
top-down:CONN: Iter:   7100,  Train Loss: 2.7e+01,  Train Acc: 62.50%,Val Loss:   7.7,  Val Acc: 26.95%, Val F1:  7.94% Time: 21.918066024780273 
 
 
top-down:TOP: Iter:   7200,  Train Loss: 2.1e+01,  Train Acc: 96.88%,Val Loss:   7.7,  Val Acc: 61.20%, Val F1: 49.52% Time: 100.75783467292786 
top-down:SEC: Iter:   7200,  Train Loss: 2.1e+01,  Train Acc: 81.25%,Val Loss:   7.7,  Val Acc: 44.64%, Val F1: 28.80% Time: 100.75783467292786 
top-down:CONN: Iter:   7200,  Train Loss: 2.1e+01,  Train Acc: 59.38%,Val Loss:   7.7,  Val Acc: 25.92%, Val F1:  7.76% Time: 100.75783467292786 
 
 
top-down:TOP: Iter:   7300,  Train Loss: 2.4e+01,  Train Acc: 100.00%,Val Loss:   7.7,  Val Acc: 61.29%, Val F1: 50.57% Time: 179.58556699752808 
top-down:SEC: Iter:   7300,  Train Loss: 2.4e+01,  Train Acc: 96.88%,Val Loss:   7.7,  Val Acc: 43.69%, Val F1: 27.87% Time: 179.58556699752808 
top-down:CONN: Iter:   7300,  Train Loss: 2.4e+01,  Train Acc: 78.12%,Val Loss:   7.7,  Val Acc: 25.41%, Val F1:  7.33% Time: 179.58556699752808 
 
 
top-down:TOP: Iter:   7400,  Train Loss: 2.8e+01,  Train Acc: 96.88%,Val Loss:   7.9,  Val Acc: 60.52%, Val F1: 49.28% Time: 258.5599489212036 
top-down:SEC: Iter:   7400,  Train Loss: 2.8e+01,  Train Acc: 90.62%,Val Loss:   7.9,  Val Acc: 43.78%, Val F1: 28.92% Time: 258.5599489212036 
top-down:CONN: Iter:   7400,  Train Loss: 2.8e+01,  Train Acc: 59.38%,Val Loss:   7.9,  Val Acc: 24.03%, Val F1:  7.39% Time: 258.5599489212036 
 
 
Train time usage: 311.35476565361023
Test time usage: 1.117257833480835
TOP: Test Loss:   9.0,  Test Acc: 57.70%, Test F1: 47.37%
SEC: Test Loss:   9.0,  Test Acc: 39.62%, Test F1: 18.15%
CONN: Test Loss:   9.0,  Test Acc: 18.87%, Test F1:  1.06%
consistency_top_sec: 23.68%,  consistency_sec_conn:  6.54%, consistency_top_sec_conn:  6.45%
              precision    recall  f1-score   support

    Temporal     0.4375    0.4000    0.4179        70
 Contingency     0.3950    0.4845    0.4352        97
  Comparison     0.4833    0.2661    0.3432       109
   Expansion     0.6692    0.7306    0.6985       360

    accuracy                         0.5770       636
   macro avg     0.4963    0.4703    0.4737       636
weighted avg     0.5700    0.5770    0.5666       636

                             precision    recall  f1-score   support

      Temporal.Asynchronous     0.4211    0.3429    0.3780        70
         Temporal.Synchrony     0.3790    0.4845    0.4253        97
          Contingency.Cause     0.0192    0.2000    0.0351         5
Contingency.Pragmatic cause     0.0000    0.0000    0.0000       104
        Comparison.Contrast     0.6679    0.5072    0.5766       345
      Comparison.Concession     0.5000    0.3333    0.4000        15

                  micro avg     0.4990    0.3962    0.4417       636
                  macro avg     0.3312    0.3113    0.3025       636
               weighted avg     0.4784    0.3962    0.4290       636

Epoch [20/30]
top-down:TOP: Iter:   7500,  Train Loss: 2.9e+01,  Train Acc: 93.75%,Val Loss:   7.9,  Val Acc: 61.29%, Val F1: 50.75% Time: 27.328857898712158 
top-down:SEC: Iter:   7500,  Train Loss: 2.9e+01,  Train Acc: 84.38%,Val Loss:   7.9,  Val Acc: 44.72%, Val F1: 28.86% Time: 27.328857898712158 
top-down:CONN: Iter:   7500,  Train Loss: 2.9e+01,  Train Acc: 46.88%,Val Loss:   7.9,  Val Acc: 24.98%, Val F1:  7.26% Time: 27.328857898712158 
 
 
top-down:TOP: Iter:   7600,  Train Loss: 2.9e+01,  Train Acc: 96.88%,Val Loss:   7.9,  Val Acc: 62.32%, Val F1: 50.97% Time: 106.31311345100403 
top-down:SEC: Iter:   7600,  Train Loss: 2.9e+01,  Train Acc: 87.50%,Val Loss:   7.9,  Val Acc: 45.06%, Val F1: 28.63% Time: 106.31311345100403 
top-down:CONN: Iter:   7600,  Train Loss: 2.9e+01,  Train Acc: 78.12%,Val Loss:   7.9,  Val Acc: 24.89%, Val F1:  6.93% Time: 106.31311345100403 
 
 
top-down:TOP: Iter:   7700,  Train Loss: 3e+01,  Train Acc: 96.88%,Val Loss:   7.8,  Val Acc: 61.72%, Val F1: 49.60% Time: 185.5296015739441 
top-down:SEC: Iter:   7700,  Train Loss: 3e+01,  Train Acc: 87.50%,Val Loss:   7.8,  Val Acc: 45.49%, Val F1: 29.65% Time: 185.5296015739441 
top-down:CONN: Iter:   7700,  Train Loss: 3e+01,  Train Acc: 59.38%,Val Loss:   7.8,  Val Acc: 25.06%, Val F1:  7.17% Time: 185.5296015739441 
 
 
top-down:TOP: Iter:   7800,  Train Loss: 2.4e+01,  Train Acc: 96.88%,Val Loss:   7.8,  Val Acc: 61.72%, Val F1: 51.61% Time: 264.4406440258026 
top-down:SEC: Iter:   7800,  Train Loss: 2.4e+01,  Train Acc: 87.50%,Val Loss:   7.8,  Val Acc: 45.84%, Val F1: 29.51% Time: 264.4406440258026 
top-down:CONN: Iter:   7800,  Train Loss: 2.4e+01,  Train Acc: 59.38%,Val Loss:   7.8,  Val Acc: 25.67%, Val F1:  7.71% Time: 264.4406440258026 
 
 
Train time usage: 311.91937613487244
Test time usage: 1.1286277770996094
TOP: Test Loss:   9.4,  Test Acc: 56.76%, Test F1: 43.44%
SEC: Test Loss:   9.4,  Test Acc: 37.58%, Test F1: 16.99%
CONN: Test Loss:   9.4,  Test Acc: 15.25%, Test F1:  0.85%
consistency_top_sec: 22.14%,  consistency_sec_conn:  5.39%, consistency_top_sec_conn:  5.29%
              precision    recall  f1-score   support

    Temporal     0.4103    0.2286    0.2936        70
 Contingency     0.3818    0.4330    0.4058        97
  Comparison     0.4754    0.2661    0.3412       109
   Expansion     0.6432    0.7611    0.6972       360

    accuracy                         0.5676       636
   macro avg     0.4777    0.4222    0.4344       636
weighted avg     0.5489    0.5676    0.5473       636

                             precision    recall  f1-score   support

      Temporal.Asynchronous     0.4651    0.2857    0.3540        70
         Temporal.Synchrony     0.3652    0.4330    0.3962        97
          Contingency.Cause     0.0175    0.2000    0.0323         5
Contingency.Pragmatic cause     0.0000    0.0000    0.0000       104
        Comparison.Contrast     0.6615    0.4986    0.5686       345
      Comparison.Concession     0.5000    0.2667    0.3478        15

                  micro avg     0.4948    0.3758    0.4272       636
                  macro avg     0.3349    0.2807    0.2831       636
               weighted avg     0.4777    0.3758    0.4163       636

Epoch [21/30]
top-down:TOP: Iter:   7900,  Train Loss: 2.4e+01,  Train Acc: 96.88%,Val Loss:   7.9,  Val Acc: 61.29%, Val F1: 50.77% Time: 32.75154423713684 
top-down:SEC: Iter:   7900,  Train Loss: 2.4e+01,  Train Acc: 93.75%,Val Loss:   7.9,  Val Acc: 44.55%, Val F1: 28.89% Time: 32.75154423713684 
top-down:CONN: Iter:   7900,  Train Loss: 2.4e+01,  Train Acc: 56.25%,Val Loss:   7.9,  Val Acc: 24.72%, Val F1:  7.60% Time: 32.75154423713684 
 
 
top-down:TOP: Iter:   8000,  Train Loss: 2.6e+01,  Train Acc: 100.00%,Val Loss:   7.9,  Val Acc: 61.80%, Val F1: 51.01% Time: 111.66495251655579 
top-down:SEC: Iter:   8000,  Train Loss: 2.6e+01,  Train Acc: 84.38%,Val Loss:   7.9,  Val Acc: 45.58%, Val F1: 29.11% Time: 111.66495251655579 
top-down:CONN: Iter:   8000,  Train Loss: 2.6e+01,  Train Acc: 75.00%,Val Loss:   7.9,  Val Acc: 25.32%, Val F1:  7.67% Time: 111.66495251655579 
 
 
top-down:TOP: Iter:   8100,  Train Loss: 3e+01,  Train Acc: 96.88%,Val Loss:   8.0,  Val Acc: 62.40%, Val F1: 52.08% Time: 190.54540371894836 
top-down:SEC: Iter:   8100,  Train Loss: 3e+01,  Train Acc: 96.88%,Val Loss:   8.0,  Val Acc: 44.55%, Val F1: 29.50% Time: 190.54540371894836 
top-down:CONN: Iter:   8100,  Train Loss: 3e+01,  Train Acc: 59.38%,Val Loss:   8.0,  Val Acc: 25.75%, Val F1:  7.50% Time: 190.54540371894836 
 
 
top-down:TOP: Iter:   8200,  Train Loss: 3.1e+01,  Train Acc: 96.88%,Val Loss:   7.9,  Val Acc: 61.37%, Val F1: 50.58% Time: 269.3966805934906 
top-down:SEC: Iter:   8200,  Train Loss: 3.1e+01,  Train Acc: 87.50%,Val Loss:   7.9,  Val Acc: 44.46%, Val F1: 28.70% Time: 269.3966805934906 
top-down:CONN: Iter:   8200,  Train Loss: 3.1e+01,  Train Acc: 65.62%,Val Loss:   7.9,  Val Acc: 25.92%, Val F1:  7.96% Time: 269.3966805934906 
 
 
Train time usage: 311.32771730422974
Test time usage: 1.0778687000274658
TOP: Test Loss:   9.3,  Test Acc: 56.29%, Test F1: 44.37%
SEC: Test Loss:   9.3,  Test Acc: 37.89%, Test F1: 17.45%
CONN: Test Loss:   9.3,  Test Acc: 17.92%, Test F1:  1.01%
consistency_top_sec: 22.23%,  consistency_sec_conn:  6.26%, consistency_top_sec_conn:  6.16%
              precision    recall  f1-score   support

    Temporal     0.4651    0.2857    0.3540        70
 Contingency     0.3468    0.4433    0.3891        97
  Comparison     0.4603    0.2661    0.3372       109
   Expansion     0.6552    0.7389    0.6945       360

    accuracy                         0.5629       636
   macro avg     0.4818    0.4335    0.4437       636
weighted avg     0.5538    0.5629    0.5492       636

                             precision    recall  f1-score   support

      Temporal.Asynchronous     0.4750    0.2714    0.3455        70
         Temporal.Synchrony     0.3511    0.4742    0.4035        97
          Contingency.Cause     0.0179    0.2000    0.0328         5
Contingency.Pragmatic cause     0.0000    0.0000    0.0000       104
        Comparison.Contrast     0.6564    0.4928    0.5629       345
      Comparison.Concession     0.5000    0.3333    0.4000        15

                  micro avg     0.4849    0.3789    0.4254       636
                  macro avg     0.3334    0.2953    0.2908       636
               weighted avg     0.4738    0.3789    0.4146       636

Epoch [22/30]
top-down:TOP: Iter:   8300,  Train Loss: 2.5e+01,  Train Acc: 96.88%,Val Loss:   8.0,  Val Acc: 61.20%, Val F1: 50.59% Time: 38.38368463516235 
top-down:SEC: Iter:   8300,  Train Loss: 2.5e+01,  Train Acc: 90.62%,Val Loss:   8.0,  Val Acc: 43.52%, Val F1: 27.62% Time: 38.38368463516235 
top-down:CONN: Iter:   8300,  Train Loss: 2.5e+01,  Train Acc: 59.38%,Val Loss:   8.0,  Val Acc: 25.92%, Val F1:  7.68% Time: 38.38368463516235 
 
 
top-down:TOP: Iter:   8400,  Train Loss: 2.9e+01,  Train Acc: 100.00%,Val Loss:   7.9,  Val Acc: 61.46%, Val F1: 50.61% Time: 117.32600712776184 
top-down:SEC: Iter:   8400,  Train Loss: 2.9e+01,  Train Acc: 90.62%,Val Loss:   7.9,  Val Acc: 44.03%, Val F1: 28.90% Time: 117.32600712776184 
top-down:CONN: Iter:   8400,  Train Loss: 2.9e+01,  Train Acc: 65.62%,Val Loss:   7.9,  Val Acc: 25.84%, Val F1:  7.84% Time: 117.32600712776184 
 
 
top-down:TOP: Iter:   8500,  Train Loss: 3.1e+01,  Train Acc: 96.88%,Val Loss:   8.0,  Val Acc: 61.12%, Val F1: 49.89% Time: 196.52586889266968 
top-down:SEC: Iter:   8500,  Train Loss: 3.1e+01,  Train Acc: 90.62%,Val Loss:   8.0,  Val Acc: 45.15%, Val F1: 29.75% Time: 196.52586889266968 
top-down:CONN: Iter:   8500,  Train Loss: 3.1e+01,  Train Acc: 78.12%,Val Loss:   8.0,  Val Acc: 25.92%, Val F1:  7.93% Time: 196.52586889266968 
 
 
top-down:TOP: Iter:   8600,  Train Loss: 2.8e+01,  Train Acc: 93.75%,Val Loss:   8.0,  Val Acc: 61.37%, Val F1: 51.27% Time: 275.48821449279785 
top-down:SEC: Iter:   8600,  Train Loss: 2.8e+01,  Train Acc: 87.50%,Val Loss:   8.0,  Val Acc: 43.86%, Val F1: 29.07% Time: 275.48821449279785 
top-down:CONN: Iter:   8600,  Train Loss: 2.8e+01,  Train Acc: 56.25%,Val Loss:   8.0,  Val Acc: 25.41%, Val F1:  7.29% Time: 275.48821449279785 
 
 
Train time usage: 312.01293754577637
Test time usage: 1.1256539821624756
TOP: Test Loss:   9.2,  Test Acc: 57.86%, Test F1: 45.11%
SEC: Test Loss:   9.2,  Test Acc: 37.89%, Test F1: 17.18%
CONN: Test Loss:   9.2,  Test Acc: 19.50%, Test F1:  1.13%
consistency_top_sec: 22.43%,  consistency_sec_conn:  6.64%, consistency_top_sec_conn:  6.64%
              precision    recall  f1-score   support

    Temporal     0.4681    0.3143    0.3761        70
 Contingency     0.3905    0.4227    0.4059        97
  Comparison     0.4561    0.2385    0.3133       109
   Expansion     0.6534    0.7750    0.7090       360

    accuracy                         0.5786       636
   macro avg     0.4920    0.4376    0.4511       636
weighted avg     0.5591    0.5786    0.5583       636

                             precision    recall  f1-score   support

      Temporal.Asynchronous     0.4490    0.3143    0.3697        70
         Temporal.Synchrony     0.3727    0.4227    0.3961        97
          Contingency.Cause     0.0192    0.2000    0.0351         5
Contingency.Pragmatic cause     0.0000    0.0000    0.0000       104
        Comparison.Contrast     0.6578    0.5014    0.5691       345
      Comparison.Concession     0.5000    0.2667    0.3478        15

                  micro avg     0.4990    0.3789    0.4307       636
                  macro avg     0.3331    0.2842    0.2863       636
               weighted avg     0.4750    0.3789    0.4183       636

Epoch [23/30]
top-down:TOP: Iter:   8700,  Train Loss: 2.7e+01,  Train Acc: 100.00%,Val Loss:   8.0,  Val Acc: 61.20%, Val F1: 51.08% Time: 43.59796929359436 
top-down:SEC: Iter:   8700,  Train Loss: 2.7e+01,  Train Acc: 100.00%,Val Loss:   8.0,  Val Acc: 44.81%, Val F1: 29.55% Time: 43.59796929359436 
top-down:CONN: Iter:   8700,  Train Loss: 2.7e+01,  Train Acc: 81.25%,Val Loss:   8.0,  Val Acc: 25.49%, Val F1:  7.70% Time: 43.59796929359436 
 
 
top-down:TOP: Iter:   8800,  Train Loss: 2.4e+01,  Train Acc: 100.00%,Val Loss:   8.0,  Val Acc: 61.37%, Val F1: 50.79% Time: 122.51936912536621 
top-down:SEC: Iter:   8800,  Train Loss: 2.4e+01,  Train Acc: 96.88%,Val Loss:   8.0,  Val Acc: 45.06%, Val F1: 30.06% Time: 122.51936912536621 
top-down:CONN: Iter:   8800,  Train Loss: 2.4e+01,  Train Acc: 62.50%,Val Loss:   8.0,  Val Acc: 25.75%, Val F1:  8.11% Time: 122.51936912536621 
 
 
top-down:TOP: Iter:   8900,  Train Loss: 2.6e+01,  Train Acc: 96.88%,Val Loss:   8.1,  Val Acc: 60.43%, Val F1: 49.68% Time: 202.0830364227295 
top-down:SEC: Iter:   8900,  Train Loss: 2.6e+01,  Train Acc: 93.75%,Val Loss:   8.1,  Val Acc: 44.12%, Val F1: 28.56% Time: 202.0830364227295 
top-down:CONN: Iter:   8900,  Train Loss: 2.6e+01,  Train Acc: 59.38%,Val Loss:   8.1,  Val Acc: 25.24%, Val F1:  7.60% Time: 202.0830364227295 
 
 
top-down:TOP: Iter:   9000,  Train Loss: 2.7e+01,  Train Acc: 100.00%,Val Loss:   8.1,  Val Acc: 60.52%, Val F1: 49.75% Time: 281.25921154022217 
top-down:SEC: Iter:   9000,  Train Loss: 2.7e+01,  Train Acc: 96.88%,Val Loss:   8.1,  Val Acc: 44.46%, Val F1: 28.96% Time: 281.25921154022217 
top-down:CONN: Iter:   9000,  Train Loss: 2.7e+01,  Train Acc: 65.62%,Val Loss:   8.1,  Val Acc: 24.55%, Val F1:  7.40% Time: 281.25921154022217 
 
 
Train time usage: 312.3161244392395
Test time usage: 1.1031849384307861
TOP: Test Loss:   9.4,  Test Acc: 56.76%, Test F1: 44.29%
SEC: Test Loss:   9.4,  Test Acc: 37.26%, Test F1: 16.58%
CONN: Test Loss:   9.4,  Test Acc: 17.92%, Test F1:  0.98%
consistency_top_sec: 21.85%,  consistency_sec_conn:  6.06%, consistency_top_sec_conn:  6.06%
              precision    recall  f1-score   support

    Temporal     0.4651    0.2857    0.3540        70
 Contingency     0.3448    0.4124    0.3756        97
  Comparison     0.5283    0.2569    0.3457       109
   Expansion     0.6439    0.7583    0.6964       360

    accuracy                         0.5676       636
   macro avg     0.4955    0.4283    0.4429       636
weighted avg     0.5588    0.5676    0.5497       636

                             precision    recall  f1-score   support

      Temporal.Asynchronous     0.4667    0.3000    0.3652        70
         Temporal.Synchrony     0.3281    0.4330    0.3733        97
          Contingency.Cause     0.0208    0.2000    0.0377         5
Contingency.Pragmatic cause     0.0000    0.0000    0.0000       104
        Comparison.Contrast     0.6576    0.4899    0.5615       345
      Comparison.Concession     0.4000    0.2667    0.3200        15

                  micro avg     0.4847    0.3726    0.4213       636
                  macro avg     0.3122    0.2816    0.2763       636
               weighted avg     0.4677    0.3726    0.4095       636

Epoch [24/30]
top-down:TOP: Iter:   9100,  Train Loss: 3.6e+01,  Train Acc: 100.00%,Val Loss:   8.2,  Val Acc: 61.37%, Val F1: 50.19% Time: 48.63870668411255 
top-down:SEC: Iter:   9100,  Train Loss: 3.6e+01,  Train Acc: 96.88%,Val Loss:   8.2,  Val Acc: 44.21%, Val F1: 29.01% Time: 48.63870668411255 
top-down:CONN: Iter:   9100,  Train Loss: 3.6e+01,  Train Acc: 87.50%,Val Loss:   8.2,  Val Acc: 25.41%, Val F1:  7.56% Time: 48.63870668411255 
 
 
top-down:TOP: Iter:   9200,  Train Loss: 2.3e+01,  Train Acc: 93.75%,Val Loss:   8.2,  Val Acc: 60.69%, Val F1: 49.87% Time: 127.30664730072021 
top-down:SEC: Iter:   9200,  Train Loss: 2.3e+01,  Train Acc: 87.50%,Val Loss:   8.2,  Val Acc: 43.86%, Val F1: 28.77% Time: 127.30664730072021 
top-down:CONN: Iter:   9200,  Train Loss: 2.3e+01,  Train Acc: 50.00%,Val Loss:   8.2,  Val Acc: 24.98%, Val F1:  7.17% Time: 127.30664730072021 
 
 
top-down:TOP: Iter:   9300,  Train Loss: 2.5e+01,  Train Acc: 96.88%,Val Loss:   8.2,  Val Acc: 61.12%, Val F1: 50.57% Time: 206.25833177566528 
top-down:SEC: Iter:   9300,  Train Loss: 2.5e+01,  Train Acc: 90.62%,Val Loss:   8.2,  Val Acc: 43.61%, Val F1: 28.73% Time: 206.25833177566528 
top-down:CONN: Iter:   9300,  Train Loss: 2.5e+01,  Train Acc: 59.38%,Val Loss:   8.2,  Val Acc: 24.89%, Val F1:  7.38% Time: 206.25833177566528 
 
 
top-down:TOP: Iter:   9400,  Train Loss: 2.5e+01,  Train Acc: 96.88%,Val Loss:   8.2,  Val Acc: 61.63%, Val F1: 51.07% Time: 284.90582394599915 
top-down:SEC: Iter:   9400,  Train Loss: 2.5e+01,  Train Acc: 96.88%,Val Loss:   8.2,  Val Acc: 44.89%, Val F1: 28.98% Time: 284.90582394599915 
top-down:CONN: Iter:   9400,  Train Loss: 2.5e+01,  Train Acc: 78.12%,Val Loss:   8.2,  Val Acc: 25.58%, Val F1:  7.76% Time: 284.90582394599915 
 
 
Train time usage: 310.5404875278473
Test time usage: 1.101546287536621
TOP: Test Loss:   9.7,  Test Acc: 56.92%, Test F1: 45.57%
SEC: Test Loss:   9.7,  Test Acc: 37.26%, Test F1: 17.05%
CONN: Test Loss:   9.7,  Test Acc: 14.94%, Test F1:  0.84%
consistency_top_sec: 21.66%,  consistency_sec_conn:  5.20%, consistency_top_sec_conn:  5.10%
              precision    recall  f1-score   support

    Temporal     0.4783    0.3143    0.3793        70
 Contingency     0.3750    0.4330    0.4019        97
  Comparison     0.4839    0.2752    0.3509       109
   Expansion     0.6442    0.7444    0.6907       360

    accuracy                         0.5692       636
   macro avg     0.4953    0.4417    0.4557       636
weighted avg     0.5574    0.5692    0.5542       636

                             precision    recall  f1-score   support

      Temporal.Asynchronous     0.4783    0.3143    0.3793        70
         Temporal.Synchrony     0.3644    0.4433    0.4000        97
          Contingency.Cause     0.0328    0.4000    0.0606         5
Contingency.Pragmatic cause     0.0000    0.0000    0.0000       104
        Comparison.Contrast     0.6614    0.4812    0.5570       345
      Comparison.Concession     0.3636    0.2667    0.3077        15

                  micro avg     0.4857    0.3726    0.4217       636
                  macro avg     0.3167    0.3176    0.2841       636
               weighted avg     0.4758    0.3726    0.4127       636

Epoch [25/30]
top-down:TOP: Iter:   9500,  Train Loss: 2.8e+01,  Train Acc: 96.88%,Val Loss:   8.1,  Val Acc: 61.46%, Val F1: 50.20% Time: 53.91876459121704 
top-down:SEC: Iter:   9500,  Train Loss: 2.8e+01,  Train Acc: 90.62%,Val Loss:   8.1,  Val Acc: 44.29%, Val F1: 28.73% Time: 53.91876459121704 
top-down:CONN: Iter:   9500,  Train Loss: 2.8e+01,  Train Acc: 53.12%,Val Loss:   8.1,  Val Acc: 24.89%, Val F1:  7.31% Time: 53.91876459121704 
 
 
top-down:TOP: Iter:   9600,  Train Loss: 2.7e+01,  Train Acc: 93.75%,Val Loss:   8.2,  Val Acc: 61.55%, Val F1: 50.90% Time: 132.16172695159912 
top-down:SEC: Iter:   9600,  Train Loss: 2.7e+01,  Train Acc: 90.62%,Val Loss:   8.2,  Val Acc: 44.38%, Val F1: 29.26% Time: 132.16172695159912 
top-down:CONN: Iter:   9600,  Train Loss: 2.7e+01,  Train Acc: 65.62%,Val Loss:   8.2,  Val Acc: 25.15%, Val F1:  7.65% Time: 132.16172695159912 
 
 
top-down:TOP: Iter:   9700,  Train Loss: 2.5e+01,  Train Acc: 100.00%,Val Loss:   8.3,  Val Acc: 61.03%, Val F1: 50.39% Time: 210.5407919883728 
top-down:SEC: Iter:   9700,  Train Loss: 2.5e+01,  Train Acc: 96.88%,Val Loss:   8.3,  Val Acc: 43.69%, Val F1: 27.52% Time: 210.5407919883728 
top-down:CONN: Iter:   9700,  Train Loss: 2.5e+01,  Train Acc: 62.50%,Val Loss:   8.3,  Val Acc: 25.84%, Val F1:  7.60% Time: 210.5407919883728 
 
 
top-down:TOP: Iter:   9800,  Train Loss: 2.2e+01,  Train Acc: 96.88%,Val Loss:   8.2,  Val Acc: 61.12%, Val F1: 50.14% Time: 289.76263213157654 
top-down:SEC: Iter:   9800,  Train Loss: 2.2e+01,  Train Acc: 96.88%,Val Loss:   8.2,  Val Acc: 44.29%, Val F1: 28.94% Time: 289.76263213157654 
top-down:CONN: Iter:   9800,  Train Loss: 2.2e+01,  Train Acc: 81.25%,Val Loss:   8.2,  Val Acc: 26.09%, Val F1:  7.80% Time: 289.76263213157654 
 
 
Train time usage: 310.06938433647156
Test time usage: 1.1098358631134033
TOP: Test Loss:   9.8,  Test Acc: 56.92%, Test F1: 45.98%
SEC: Test Loss:   9.8,  Test Acc: 37.42%, Test F1: 16.85%
CONN: Test Loss:   9.8,  Test Acc: 15.88%, Test F1:  0.83%
consistency_top_sec: 22.04%,  consistency_sec_conn:  5.68%, consistency_top_sec_conn:  5.68%
              precision    recall  f1-score   support

    Temporal     0.4694    0.3286    0.3866        70
 Contingency     0.3710    0.4742    0.4163        97
  Comparison     0.4915    0.2661    0.3452       109
   Expansion     0.6535    0.7333    0.6911       360

    accuracy                         0.5692       636
   macro avg     0.4963    0.4505    0.4598       636
weighted avg     0.5624    0.5692    0.5564       636

                             precision    recall  f1-score   support

      Temporal.Asynchronous     0.4423    0.3286    0.3770        70
         Temporal.Synchrony     0.3481    0.4845    0.4052        97
          Contingency.Cause     0.0185    0.2000    0.0339         5
Contingency.Pragmatic cause     0.0000    0.0000    0.0000       104
        Comparison.Contrast     0.6546    0.4725    0.5488       345
      Comparison.Concession     0.4000    0.2667    0.3200        15

                  micro avg     0.4760    0.3742    0.4190       636
                  macro avg     0.3106    0.2920    0.2808       636
               weighted avg     0.4665    0.3742    0.4088       636

Epoch [26/30]
top-down:TOP: Iter:   9900,  Train Loss: 2.8e+01,  Train Acc: 100.00%,Val Loss:   8.2,  Val Acc: 61.46%, Val F1: 51.43% Time: 59.50513052940369 
top-down:SEC: Iter:   9900,  Train Loss: 2.8e+01,  Train Acc: 93.75%,Val Loss:   8.2,  Val Acc: 44.38%, Val F1: 27.83% Time: 59.50513052940369 
top-down:CONN: Iter:   9900,  Train Loss: 2.8e+01,  Train Acc: 71.88%,Val Loss:   8.2,  Val Acc: 26.61%, Val F1:  8.26% Time: 59.50513052940369 
 
 
top-down:TOP: Iter:  10000,  Train Loss: 2.6e+01,  Train Acc: 96.88%,Val Loss:   8.2,  Val Acc: 61.72%, Val F1: 51.36% Time: 138.35462427139282 
top-down:SEC: Iter:  10000,  Train Loss: 2.6e+01,  Train Acc: 93.75%,Val Loss:   8.2,  Val Acc: 45.15%, Val F1: 28.57% Time: 138.35462427139282 
top-down:CONN: Iter:  10000,  Train Loss: 2.6e+01,  Train Acc: 71.88%,Val Loss:   8.2,  Val Acc: 26.35%, Val F1:  7.96% Time: 138.35462427139282 
 
 
top-down:TOP: Iter:  10100,  Train Loss: 2.7e+01,  Train Acc: 96.88%,Val Loss:   8.2,  Val Acc: 61.29%, Val F1: 50.58% Time: 216.68434524536133 
top-down:SEC: Iter:  10100,  Train Loss: 2.7e+01,  Train Acc: 100.00%,Val Loss:   8.2,  Val Acc: 44.98%, Val F1: 28.05% Time: 216.68434524536133 
top-down:CONN: Iter:  10100,  Train Loss: 2.7e+01,  Train Acc: 56.25%,Val Loss:   8.2,  Val Acc: 26.78%, Val F1:  7.96% Time: 216.68434524536133 
 
 
top-down:TOP: Iter:  10200,  Train Loss: 2.8e+01,  Train Acc: 96.88%,Val Loss:   8.2,  Val Acc: 60.77%, Val F1: 48.99% Time: 295.3752098083496 
top-down:SEC: Iter:  10200,  Train Loss: 2.8e+01,  Train Acc: 93.75%,Val Loss:   8.2,  Val Acc: 44.72%, Val F1: 29.28% Time: 295.3752098083496 
top-down:CONN: Iter:  10200,  Train Loss: 2.8e+01,  Train Acc: 75.00%,Val Loss:   8.2,  Val Acc: 25.32%, Val F1:  7.72% Time: 295.3752098083496 
 
 
Train time usage: 310.60992407798767
Test time usage: 1.0683822631835938
TOP: Test Loss:   9.8,  Test Acc: 56.92%, Test F1: 44.53%
SEC: Test Loss:   9.8,  Test Acc: 37.26%, Test F1: 16.53%
CONN: Test Loss:   9.8,  Test Acc: 15.57%, Test F1:  0.87%
consistency_top_sec: 21.85%,  consistency_sec_conn:  5.68%, consistency_top_sec_conn:  5.68%
              precision    recall  f1-score   support

    Temporal     0.4750    0.2714    0.3455        70
 Contingency     0.3628    0.4227    0.3905        97
  Comparison     0.5179    0.2661    0.3515       109
   Expansion     0.6393    0.7583    0.6938       360

    accuracy                         0.5692       636
   macro avg     0.4988    0.4296    0.4453       636
weighted avg     0.5583    0.5692    0.5505       636

                             precision    recall  f1-score   support

      Temporal.Asynchronous     0.4651    0.2857    0.3540        70
         Temporal.Synchrony     0.3445    0.4227    0.3796        97
          Contingency.Cause     0.0208    0.2000    0.0377         5
Contingency.Pragmatic cause     0.0000    0.0000    0.0000       104
        Comparison.Contrast     0.6477    0.4957    0.5616       345
      Comparison.Concession     0.4000    0.2667    0.3200        15

                  micro avg     0.4887    0.3726    0.4228       636
                  macro avg     0.3130    0.2785    0.2755       636
               weighted avg     0.4647    0.3726    0.4093       636

Epoch [27/30]
top-down:TOP: Iter:  10300,  Train Loss: 2.7e+01,  Train Acc: 96.88%,Val Loss:   8.2,  Val Acc: 61.29%, Val F1: 50.51% Time: 65.66297554969788 
top-down:SEC: Iter:  10300,  Train Loss: 2.7e+01,  Train Acc: 93.75%,Val Loss:   8.2,  Val Acc: 44.89%, Val F1: 29.01% Time: 65.66297554969788 
top-down:CONN: Iter:  10300,  Train Loss: 2.7e+01,  Train Acc: 81.25%,Val Loss:   8.2,  Val Acc: 25.75%, Val F1:  7.92% Time: 65.66297554969788 
 
 
top-down:TOP: Iter:  10400,  Train Loss: 2.8e+01,  Train Acc: 100.00%,Val Loss:   8.3,  Val Acc: 61.63%, Val F1: 51.05% Time: 144.7698369026184 
top-down:SEC: Iter:  10400,  Train Loss: 2.8e+01,  Train Acc: 96.88%,Val Loss:   8.3,  Val Acc: 44.38%, Val F1: 29.76% Time: 144.7698369026184 
top-down:CONN: Iter:  10400,  Train Loss: 2.8e+01,  Train Acc: 71.88%,Val Loss:   8.3,  Val Acc: 25.24%, Val F1:  7.70% Time: 144.7698369026184 
 
 
top-down:TOP: Iter:  10500,  Train Loss: 2.4e+01,  Train Acc: 96.88%,Val Loss:   8.2,  Val Acc: 61.55%, Val F1: 50.96% Time: 223.86003875732422 
top-down:SEC: Iter:  10500,  Train Loss: 2.4e+01,  Train Acc: 90.62%,Val Loss:   8.2,  Val Acc: 44.89%, Val F1: 28.73% Time: 223.86003875732422 
top-down:CONN: Iter:  10500,  Train Loss: 2.4e+01,  Train Acc: 71.88%,Val Loss:   8.2,  Val Acc: 25.92%, Val F1:  7.76% Time: 223.86003875732422 
 
 
top-down:TOP: Iter:  10600,  Train Loss: 3.3e+01,  Train Acc: 96.88%,Val Loss:   8.2,  Val Acc: 61.20%, Val F1: 50.50% Time: 302.71187448501587 
top-down:SEC: Iter:  10600,  Train Loss: 3.3e+01,  Train Acc: 84.38%,Val Loss:   8.2,  Val Acc: 44.98%, Val F1: 29.94% Time: 302.71187448501587 
top-down:CONN: Iter:  10600,  Train Loss: 3.3e+01,  Train Acc: 68.75%,Val Loss:   8.2,  Val Acc: 25.92%, Val F1:  8.24% Time: 302.71187448501587 
 
 
Train time usage: 312.36494851112366
Test time usage: 1.0949325561523438
TOP: Test Loss:   9.8,  Test Acc: 57.08%, Test F1: 45.13%
SEC: Test Loss:   9.8,  Test Acc: 36.95%, Test F1: 16.35%
CONN: Test Loss:   9.8,  Test Acc: 15.25%, Test F1:  0.85%
consistency_top_sec: 21.46%,  consistency_sec_conn:  5.39%, consistency_top_sec_conn:  5.39%
              precision    recall  f1-score   support

    Temporal     0.4773    0.3000    0.3684        70
 Contingency     0.3628    0.4227    0.3905        97
  Comparison     0.5179    0.2661    0.3515       109
   Expansion     0.6430    0.7556    0.6948       360

    accuracy                         0.5708       636
   macro avg     0.5002    0.4361    0.4513       636
weighted avg     0.5606    0.5708    0.5536       636

                             precision    recall  f1-score   support

      Temporal.Asynchronous     0.4490    0.3143    0.3697        70
         Temporal.Synchrony     0.3333    0.4330    0.3767        97
          Contingency.Cause     0.0196    0.2000    0.0357         5
Contingency.Pragmatic cause     0.0000    0.0000    0.0000       104
        Comparison.Contrast     0.6587    0.4812    0.5561       345
      Comparison.Concession     0.3333    0.2667    0.2963        15

                  micro avg     0.4796    0.3695    0.4174       636
                  macro avg     0.2990    0.2825    0.2724       636
               weighted avg     0.4656    0.3695    0.4071       636

Epoch [28/30]
top-down:TOP: Iter:  10700,  Train Loss: 2.9e+01,  Train Acc: 96.88%,Val Loss:   8.2,  Val Acc: 61.80%, Val F1: 50.81% Time: 70.40201425552368 
top-down:SEC: Iter:  10700,  Train Loss: 2.9e+01,  Train Acc: 93.75%,Val Loss:   8.2,  Val Acc: 44.64%, Val F1: 29.01% Time: 70.40201425552368 
top-down:CONN: Iter:  10700,  Train Loss: 2.9e+01,  Train Acc: 71.88%,Val Loss:   8.2,  Val Acc: 25.75%, Val F1:  7.86% Time: 70.40201425552368 
 
 
top-down:TOP: Iter:  10800,  Train Loss: 2.6e+01,  Train Acc: 100.00%,Val Loss:   8.2,  Val Acc: 60.86%, Val F1: 50.54% Time: 149.05094718933105 
top-down:SEC: Iter:  10800,  Train Loss: 2.6e+01,  Train Acc: 93.75%,Val Loss:   8.2,  Val Acc: 44.03%, Val F1: 28.13% Time: 149.05094718933105 
top-down:CONN: Iter:  10800,  Train Loss: 2.6e+01,  Train Acc: 65.62%,Val Loss:   8.2,  Val Acc: 25.92%, Val F1:  7.84% Time: 149.05094718933105 
 
 
top-down:TOP: Iter:  10900,  Train Loss: 2.6e+01,  Train Acc: 96.88%,Val Loss:   8.2,  Val Acc: 61.12%, Val F1: 50.78% Time: 227.51750373840332 
top-down:SEC: Iter:  10900,  Train Loss: 2.6e+01,  Train Acc: 87.50%,Val Loss:   8.2,  Val Acc: 44.81%, Val F1: 28.70% Time: 227.51750373840332 
top-down:CONN: Iter:  10900,  Train Loss: 2.6e+01,  Train Acc: 71.88%,Val Loss:   8.2,  Val Acc: 25.75%, Val F1:  7.93% Time: 227.51750373840332 
 
 
top-down:TOP: Iter:  11000,  Train Loss: 2.2e+01,  Train Acc: 96.88%,Val Loss:   8.3,  Val Acc: 61.20%, Val F1: 50.83% Time: 306.0622456073761 
top-down:SEC: Iter:  11000,  Train Loss: 2.2e+01,  Train Acc: 96.88%,Val Loss:   8.3,  Val Acc: 44.12%, Val F1: 28.10% Time: 306.0622456073761 
top-down:CONN: Iter:  11000,  Train Loss: 2.2e+01,  Train Acc: 87.50%,Val Loss:   8.3,  Val Acc: 25.75%, Val F1:  7.69% Time: 306.0622456073761 
 
 
Train time usage: 310.168306350708
Test time usage: 1.096876859664917
TOP: Test Loss:   9.9,  Test Acc: 56.76%, Test F1: 45.69%
SEC: Test Loss:   9.9,  Test Acc: 37.89%, Test F1: 17.11%
CONN: Test Loss:   9.9,  Test Acc: 15.09%, Test F1:  0.85%
consistency_top_sec: 22.04%,  consistency_sec_conn:  5.68%, consistency_top_sec_conn:  5.58%
              precision    recall  f1-score   support

    Temporal     0.4615    0.3429    0.3934        70
 Contingency     0.3509    0.4124    0.3791        97
  Comparison     0.5455    0.2752    0.3659       109
   Expansion     0.6434    0.7417    0.6890       360

    accuracy                         0.5676       636
   macro avg     0.5003    0.4430    0.4569       636
weighted avg     0.5620    0.5676    0.5538       636

                             precision    recall  f1-score   support

      Temporal.Asynchronous     0.4561    0.3714    0.4094        70
         Temporal.Synchrony     0.3445    0.4227    0.3796        97
          Contingency.Cause     0.0200    0.2000    0.0364         5
Contingency.Pragmatic cause     0.0000    0.0000    0.0000       104
        Comparison.Contrast     0.6680    0.4899    0.5652       345
      Comparison.Concession     0.4000    0.2667    0.3200        15

                  micro avg     0.4918    0.3789    0.4281       636
                  macro avg     0.3148    0.2918    0.2851       636
               weighted avg     0.4747    0.3789    0.4174       636

Epoch [29/30]
top-down:TOP: Iter:  11100,  Train Loss: 3.4e+01,  Train Acc: 100.00%,Val Loss:   8.2,  Val Acc: 61.29%, Val F1: 50.82% Time: 75.42729496955872 
top-down:SEC: Iter:  11100,  Train Loss: 3.4e+01,  Train Acc: 96.88%,Val Loss:   8.2,  Val Acc: 44.81%, Val F1: 28.83% Time: 75.42729496955872 
top-down:CONN: Iter:  11100,  Train Loss: 3.4e+01,  Train Acc: 81.25%,Val Loss:   8.2,  Val Acc: 25.75%, Val F1:  7.66% Time: 75.42729496955872 
 
 
top-down:TOP: Iter:  11200,  Train Loss: 3.1e+01,  Train Acc: 100.00%,Val Loss:   8.2,  Val Acc: 61.03%, Val F1: 50.64% Time: 154.65961027145386 
top-down:SEC: Iter:  11200,  Train Loss: 3.1e+01,  Train Acc: 100.00%,Val Loss:   8.2,  Val Acc: 44.46%, Val F1: 28.49% Time: 154.65961027145386 
top-down:CONN: Iter:  11200,  Train Loss: 3.1e+01,  Train Acc: 71.88%,Val Loss:   8.2,  Val Acc: 25.67%, Val F1:  7.78% Time: 154.65961027145386 
 
 
top-down:TOP: Iter:  11300,  Train Loss: 2.9e+01,  Train Acc: 100.00%,Val Loss:   8.3,  Val Acc: 61.20%, Val F1: 50.65% Time: 233.81068468093872 
top-down:SEC: Iter:  11300,  Train Loss: 2.9e+01,  Train Acc: 96.88%,Val Loss:   8.3,  Val Acc: 44.81%, Val F1: 29.07% Time: 233.81068468093872 
top-down:CONN: Iter:  11300,  Train Loss: 2.9e+01,  Train Acc: 65.62%,Val Loss:   8.3,  Val Acc: 25.84%, Val F1:  7.78% Time: 233.81068468093872 
 
 
Train time usage: 309.6615409851074
Test time usage: 1.100907564163208
TOP: Test Loss: 1e+01,  Test Acc: 57.08%, Test F1: 45.74%
SEC: Test Loss: 1e+01,  Test Acc: 37.26%, Test F1: 17.03%
CONN: Test Loss: 1e+01,  Test Acc: 14.62%, Test F1:  0.80%
consistency_top_sec: 21.85%,  consistency_sec_conn:  5.10%, consistency_top_sec_conn:  5.00%
              precision    recall  f1-score   support

    Temporal     0.4583    0.3143    0.3729        70
 Contingency     0.3707    0.4433    0.4038        97
  Comparison     0.5263    0.2752    0.3614       109
   Expansion     0.6458    0.7444    0.6916       360

    accuracy                         0.5708       636
   macro avg     0.5003    0.4443    0.4574       636
weighted avg     0.5627    0.5708    0.5560       636

                             precision    recall  f1-score   support

      Temporal.Asynchronous     0.4902    0.3571    0.4132        70
         Temporal.Synchrony     0.3415    0.4330    0.3818        97
          Contingency.Cause     0.0185    0.2000    0.0339         5
Contingency.Pragmatic cause     0.0000    0.0000    0.0000       104
        Comparison.Contrast     0.6574    0.4783    0.5537       345
      Comparison.Concession     0.4000    0.2667    0.3200        15

                  micro avg     0.4837    0.3726    0.4210       636
                  macro avg     0.3179    0.2892    0.2838       636
               weighted avg     0.4722    0.3726    0.4119       636

Epoch [30/30]
top-down:TOP: Iter:  11400,  Train Loss: 2.8e+01,  Train Acc: 96.88%,Val Loss:   8.3,  Val Acc: 60.94%, Val F1: 50.88% Time: 4.1658148765563965 
top-down:SEC: Iter:  11400,  Train Loss: 2.8e+01,  Train Acc: 84.38%,Val Loss:   8.3,  Val Acc: 44.29%, Val F1: 28.58% Time: 4.1658148765563965 
top-down:CONN: Iter:  11400,  Train Loss: 2.8e+01,  Train Acc: 59.38%,Val Loss:   8.3,  Val Acc: 25.75%, Val F1:  7.85% Time: 4.1658148765563965 
 
 
top-down:TOP: Iter:  11500,  Train Loss: 2.6e+01,  Train Acc: 100.00%,Val Loss:   8.3,  Val Acc: 60.86%, Val F1: 50.62% Time: 82.87485003471375 
top-down:SEC: Iter:  11500,  Train Loss: 2.6e+01,  Train Acc: 100.00%,Val Loss:   8.3,  Val Acc: 44.03%, Val F1: 28.30% Time: 82.87485003471375 
top-down:CONN: Iter:  11500,  Train Loss: 2.6e+01,  Train Acc: 65.62%,Val Loss:   8.3,  Val Acc: 25.75%, Val F1:  7.81% Time: 82.87485003471375 
 
 
top-down:TOP: Iter:  11600,  Train Loss: 2.3e+01,  Train Acc: 100.00%,Val Loss:   8.2,  Val Acc: 60.86%, Val F1: 50.42% Time: 162.26637601852417 
top-down:SEC: Iter:  11600,  Train Loss: 2.3e+01,  Train Acc: 93.75%,Val Loss:   8.2,  Val Acc: 44.03%, Val F1: 28.38% Time: 162.26637601852417 
top-down:CONN: Iter:  11600,  Train Loss: 2.3e+01,  Train Acc: 84.38%,Val Loss:   8.2,  Val Acc: 26.09%, Val F1:  7.88% Time: 162.26637601852417 
 
 
top-down:TOP: Iter:  11700,  Train Loss: 2.5e+01,  Train Acc: 96.88%,Val Loss:   8.3,  Val Acc: 61.03%, Val F1: 50.82% Time: 242.04267501831055 
top-down:SEC: Iter:  11700,  Train Loss: 2.5e+01,  Train Acc: 96.88%,Val Loss:   8.3,  Val Acc: 44.12%, Val F1: 28.37% Time: 242.04267501831055 
top-down:CONN: Iter:  11700,  Train Loss: 2.5e+01,  Train Acc: 68.75%,Val Loss:   8.3,  Val Acc: 26.09%, Val F1:  7.98% Time: 242.04267501831055 
 
 
No optimization for a long time, auto-stopping...
dev_best_acc_top: 62.92%,  dev_best_f1_top: 51.67%, 
dev_best_acc_sec: 49.18%,  dev_best_f1_sec: 30.39%, 
dev_best_acc_conn: 26.95%,  dev_best_f1_conn:  5.49%
